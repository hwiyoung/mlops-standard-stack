"""
MLOps Web Dashboard
Streamlit ê¸°ë°˜ MLOps í†µí•© ëŒ€ì‹œë³´ë“œ

Tabs:
1. Data Manager - MinIO ë°ì´í„° ì—…ë¡œë“œ/ì¡°íšŒ
2. Training Lab - í•™ìŠµ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§
3. Model Registry - MLflow ëª¨ë¸ ê´€ë¦¬
4. Inference - ì¶”ë¡  ë° ì‹œê°í™”
"""

import os
import sys
import subprocess
import threading
import queue
import time
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict

import streamlit as st
import pandas as pd
import yaml

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# .env ë¡œë“œ
from dotenv import load_dotenv
env_file = PROJECT_ROOT / ".env"
if env_file.exists():
    load_dotenv(env_file)

# ì™¸ë¶€ ì ‘ê·¼ì„ ìœ„í•œ ê³µì¸ IP ì„¤ì •
# ì™¸ë¶€ ì ‘ê·¼ì„ ìœ„í•œ ê³µì¸ IP ì„¤ì •
def get_default_public_ip():
    # 1. ë¸Œë¼ìš°ì € ì ‘ì† ê¸°ë°˜ ê°ì§€ (Streamlit 1.34+) - ìµœìš°ì„ 
    try:
        host = st.context.headers.get("host", "")
        if host:
            if ":" in host:
                ip = host.split(":")[0]
            else:
                ip = host
            # ë‚´ë¶€/ë¡œì»¬ ì£¼ì†ŒëŠ” ë¬´ì‹œí•˜ê³  ì‹¤ì œ IPì¸ ê²½ìš°ë§Œ ë°˜í™˜
            if ip not in ["localhost", "127.0.0.1", "mlflow", "minio", "0.0.0.0"]:
                return ip
    except:
        pass

    # 2. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    env_ip = os.getenv("PUBLIC_IP")
    if env_ip and env_ip not in ["localhost", "127.0.0.1", "mlflow", "minio"]:
        return env_ip
        
    # 3. ì†Œì¼“ ê¸°ë°˜ ê°ì§€ (ì„œë²„ì˜ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ IP)
    import socket
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except:
        return "localhost"

# ê¸°ë³¸ IP ì´ˆê¸°í™” (ì„¸ì…˜ ìƒíƒœ ì €ì¥)
if "public_ip" not in st.session_state:
    st.session_state.public_ip = get_default_public_ip()

PUBLIC_IP = st.session_state.public_ip
MLFLOW_PORT = os.getenv("MLFLOW_PORT", "5000")
MINIO_CONSOLE_PORT = os.getenv("MINIO_CONSOLE_PORT", "9001")
MINIO_API_PORT = os.getenv("MINIO_API_PORT", "9000")

from src.models.gaussian_model import GaussianModel, GaussianModelConfig
# ============================================
# í˜ì´ì§€ ì„¤ì •
# ============================================
st.set_page_config(
    page_title="MLOps Dashboard",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 1rem;
        color: white;
        text-align: center;
    }
    .status-running {
        color: #ffa500;
        font-weight: bold;
    }
    .status-success {
        color: #00c853;
        font-weight: bold;
    }
    .status-error {
        color: #ff1744;
        font-weight: bold;
    }
    .log-container {
        background-color: #1e1e1e;
        color: #d4d4d4;
        font-family: 'Consolas', 'Monaco', monospace;
        padding: 1rem;
        border-radius: 0.5rem;
        height: 400px;
        overflow-y: auto;
        font-size: 0.85rem;
    }
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #1a1a2e 0%, #16213e 100%);
    }
</style>
""", unsafe_allow_html=True)


# ============================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================
def get_minio_client():
    """MinIO S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    import boto3
    return boto3.client(
        "s3",
        endpoint_url=os.getenv("MLFLOW_S3_ENDPOINT_URL", "http://localhost:9000"),
        aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID", "minioadmin"),
        aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY", "minio_secure_password_2024"),
    )


def list_minio_buckets() -> List[str]:
    """MinIO ë²„í‚· ëª©ë¡ ì¡°íšŒ"""
    try:
        s3 = get_minio_client()
        response = s3.list_buckets()
        return [b["Name"] for b in response.get("Buckets", [])]
    except Exception as e:
        st.error(f"MinIO ì—°ê²° ì‹¤íŒ¨: {e}")
        return []


def list_minio_objects(bucket: str, prefix: str = "") -> List[Dict]:
    """MinIO ê°ì²´ ëª©ë¡ ì¡°íšŒ"""
    try:
        s3 = get_minio_client()
        paginator = s3.get_paginator('list_objects_v2')
        
        objects = []
        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):
            if 'Contents' in page:
                for obj in page['Contents']:
                    objects.append({
                        "Key": obj["Key"],
                        "Size (KB)": round(obj["Size"] / 1024, 2),
                        "Last Modified": obj["LastModified"].strftime("%Y-%m-%d %H:%M")
                    })
        return objects
    except Exception as e:
        st.error(f"ê°ì²´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


def get_presigned_url(bucket: str, key: str, expires_in: int = 604800) -> str:
    """MinIO Presigned URL ìƒì„± (ì™¸ë¶€ IP ë°˜ì˜)"""
    try:
        s3 = get_minio_client()
        url = s3.generate_presigned_url(
            'get_object',
            Params={'Bucket': bucket, 'Key': key},
            ExpiresIn=expires_in
        )
        
        # ì™¸ë¶€ ì ‘ê·¼ì„ ìœ„í•´ í˜¸ìŠ¤íŠ¸ëª… êµì²´ (ëŒ€ì‹œë³´ë“œ ì„¸ì…˜ IP ê¸°ì¤€)
        public_ip = st.session_state.get("public_ip", "localhost")
        if public_ip not in ["localhost", "127.0.0.1", "mlflow", "minio"]:
            # http://minio:9000/... -> http://PUBLIC_IP:9000/...
            # replace()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ê·œì‹ ì—­ì°¸ì¡° ë¬¸ì œ ë°©ì§€
            url = url.replace("http://minio:9000", f"http://{public_ip}:9000")
            url = url.replace("http://localhost:9000", f"http://{public_ip}:9000")
            
        return url
    except Exception as e:
        st.error(f"ë§í¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return ""


def get_config_files() -> List[str]:
    """configs/ í´ë”ì˜ YAML íŒŒì¼ ëª©ë¡"""
    configs_dir = PROJECT_ROOT / "configs"
    if configs_dir.exists():
        return [f.name for f in configs_dir.glob("*.yaml")]
    return []


def load_config(config_name: str) -> dict:
    """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    config_path = PROJECT_ROOT / "configs" / config_name
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def run_command_async(cmd: List[str], cwd: str = None) -> subprocess.Popen:
    """ë¹„ë™ê¸° ëª…ë ¹ì–´ ì‹¤í–‰"""
    return subprocess.Popen(
        cmd,
        cwd=cwd or str(PROJECT_ROOT),
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1
    )


def get_data_directories() -> List[str]:
    """./data ë””ë ‰í† ë¦¬ì˜ í•˜ìœ„ ë””ë ‰í† ë¦¬ ëª©ë¡"""
    data_dir = PROJECT_ROOT / "data"
    if data_dir.exists():
        return [d.name for d in data_dir.iterdir() if d.is_dir()]
    return []


def get_mlflow_runs(experiment_name: str = None, max_results: int = 10) -> pd.DataFrame:
    """MLflow ìµœê·¼ ì‹¤í—˜ ê²°ê³¼ ì¡°íšŒ"""
    try:
        import mlflow
        mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000"))
        
        client = mlflow.tracking.MlflowClient()
        
        if experiment_name:
            exp = client.get_experiment_by_name(experiment_name)
            if exp:
                runs = client.search_runs(
                    experiment_ids=[exp.experiment_id],
                    max_results=max_results,
                    order_by=["start_time DESC"]
                )
            else:
                return pd.DataFrame()
        else:
            # ëª¨ë“  ì‹¤í—˜
            experiments = client.search_experiments()
            exp_ids = [e.experiment_id for e in experiments if e.experiment_id != "0"]
            if not exp_ids:
                return pd.DataFrame()
            runs = client.search_runs(
                experiment_ids=exp_ids,
                max_results=max_results,
                order_by=["start_time DESC"]
            )
        
        data = []
        for run in runs:
            metrics = run.data.metrics
            data.append({
                "Run ID": run.info.run_id[:8] + "...",
                "Full Run ID": run.info.run_id,
                "Name": run.info.run_name or "N/A",
                "Experiment": run.info.experiment_id,
                "Status": run.info.status,
                "PSNR": metrics.get("final_psnr") or metrics.get("psnr", "-"),
                "IoU": metrics.get("val_iou", "-"),
                "Duration": f"{(run.info.end_time - run.info.start_time) / 1000:.0f}s" if run.info.end_time else "-"
            })
        
        return pd.DataFrame(data)
    except Exception as e:
        st.error(f"MLflow ì—°ê²° ì‹¤íŒ¨: {e}")
        return pd.DataFrame()


# ============================================
# ì‚¬ì´ë“œë°”
# ============================================
with st.sidebar:
    st.markdown("## ğŸš€ MLOps Dashboard")
    st.markdown("---")
    
    # íƒ­ ì„ íƒ
    selected_tab = st.radio(
        "ë©”ë‰´ ì„ íƒ",
        ["ğŸ“‚ Data Manager", "ğŸ“ ì§€ë„ ë¸Œë¼ìš°ì €", "ğŸ”¬ Training Lab", "ğŸ“¦ Model Registry", "ğŸ”® Inference"],
        label_visibility="collapsed"
    )
    
    st.markdown("---")
    
    # ìƒíƒœ í‘œì‹œ
    st.markdown("### ğŸ”Œ ì„œë¹„ìŠ¤ ìƒíƒœ")
    
    # MinIO ìƒíƒœ
    try:
        buckets = list_minio_buckets()
        st.success(f"âœ… MinIO ({len(buckets)} buckets)")
    except:
        st.error("âŒ MinIO")
    
    # MLflow ìƒíƒœ
    try:
        import mlflow
        mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000"))
        experiments = mlflow.tracking.MlflowClient().search_experiments()
        st.success(f"âœ… MLflow ({len(experiments)} experiments)")
    except:
        st.error("âŒ MLflow")
    
    st.markdown("---")
    st.markdown("### ğŸŒ ë„¤íŠ¸ì›Œí¬ ì„¤ì •")
    
    # í—¬í”„ í…ìŠ¤íŠ¸ ì¶”ê°€
    st.info("ğŸ’¡ ë‹¤ë¥¸ ì»´í“¨í„°ì—ì„œ ì ‘ì† ì¤‘ì´ë¼ë©´ ì•„ë˜ IPê°€ ì„œë²„ì˜ ì‹¤ì œ IPì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    new_ip = st.text_input("ì„œë²„ IP (Server Host)", value=st.session_state.public_ip, help="ì™¸ë¶€ ì ‘ì† ì‹œ ë§í¬ê°€ ìƒì„±ë  IP ì£¼ì†Œì…ë‹ˆë‹¤.")
    if new_ip != st.session_state.public_ip:
        st.session_state.public_ip = new_ip
        st.rerun()

    st.markdown("##### ğŸ”— Quick Links (ë¯¸ë¦¬ë³´ê¸°)")
    mlflow_ui_url = f"http://{st.session_state.public_ip}:{MLFLOW_PORT}"
    minio_ui_url = f"http://{st.session_state.public_ip}:{MINIO_CONSOLE_PORT}"
    
    st.markdown(f"- [ğŸ“Š MLflow UI]({mlflow_ui_url})")
    st.markdown(f"- [ğŸ“¦ MinIO Console]({minio_ui_url})")
    
    if st.session_state.public_ip in ["localhost", "127.0.0.1", "mlflow"]:
        st.warning("âš ï¸ í˜„ì¬ ë¡œì»¬/ë‚´ë¶€ ì£¼ì†Œë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ ì™¸ë¶€ ì ‘ì† ì‹œ ë§í¬ê°€ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# ============================================
# Tab 1: Data Manager
# ============================================
if selected_tab == "ğŸ“‚ Data Manager":
    st.markdown('<h1 class="main-header">ğŸ“‚ Data Manager</h1>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ")
        st.caption("ë¡œì»¬ í´ë”ë¥¼ MinIO ë²„í‚·ìœ¼ë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤. ëŒ€ìš©ëŸ‰ íŒŒì¼ë„ ì•ˆì •ì ìœ¼ë¡œ ì „ì†¡!")
        
        # ë¡œì»¬ í´ë” ëª©ë¡ ì¡°íšŒ (/workspace/data í•˜ìœ„)
        try:
            data_root = Path("/workspace/data")
            if data_root.exists():
                # ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ íƒìƒ‰
                subdirs = sorted([d for d in data_root.rglob("*") if d.is_dir()])
                local_folder_options = [str(d) for d in subdirs]
            else:
                local_folder_options = []
        except:
            local_folder_options = []
            
        with st.form("upload_form"):
            if local_folder_options:
                source_path = st.selectbox("ğŸ“ ë¡œì»¬ í´ë” ì„ íƒ", local_folder_options, 
                                           help="/workspace/data í•˜ìœ„ì˜ í´ë” ì¤‘ ì—…ë¡œë“œí•  ëŒ€ìƒì„ ì„ íƒí•˜ì„¸ìš”.")
            else:
                source_path = st.text_input("ğŸ“ ë¡œì»¬ í´ë” ê²½ë¡œ", placeholder="/workspace/data/folder_name", 
                                            help="ì—…ë¡œë“œí•  íŒŒì¼ë“¤ì´ ìˆëŠ” ë¡œì»¬ ì»´í“¨í„°ì˜ í´ë” ê²½ë¡œ")
                
            bucket = st.selectbox("ğŸª£ ëŒ€ìƒ ë²„í‚·", ["raw-data", "raw-data-nvs", "processed-data"],
                                  help="MinIOì—ì„œ íŒŒì¼ì„ ì €ì¥í•  ë²„í‚·")
            prefix = st.text_input("ğŸ“‚ ë²„í‚· ë‚´ ì €ì¥ ê²½ë¡œ", placeholder="project_name/",
                                   help="ë²„í‚· ì•ˆì—ì„œ íŒŒì¼ë“¤ì´ ì €ì¥ë  í´ë” ê²½ë¡œ (ë³´í†µ í´ë”ëª…ê³¼ ë™ì¼í•˜ê²Œ ì…ë ¥)")
            
            st.markdown("##### âš™ï¸ ì˜µì…˜")
            overwrite = st.checkbox("ê¸°ì¡´ íŒŒì¼ ë®ì–´ì“°ê¸°", value=False, help="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì„ ë®ì–´ì”ë‹ˆë‹¤ (ê¸°ë³¸: ê±´ë„ˆëœ€)")
            
            upload_btn = st.form_submit_button("ğŸš€ ì—…ë¡œë“œ ì‹¤í–‰", use_container_width=True, type="primary")
        
        if upload_btn and source_path:
            if not Path(source_path).exists():
                st.error(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_path}")
            else:
                # íŒŒì¼ ìˆ˜ ë° í¬ê¸° ê³„ì‚°
                files = list(Path(source_path).rglob("*"))
                file_count = len([f for f in files if f.is_file()])
                total_size = sum(f.stat().st_size for f in files if f.is_file())
                
                st.info(f"ğŸ“Š {file_count}ê°œ íŒŒì¼, ì´ {total_size / (1024*1024):.1f} MB")
                
                # mc ëª…ë ¹ì–´ êµ¬ì„± (ê¸°ë³¸ì ìœ¼ë¡œ ê¸°ì¡´ íŒŒì¼ì€ ê±´ë„ˆëœ€)
                mc_args = ["mc", "mirror"]
                if overwrite:
                    mc_args.append("--overwrite")
                mc_args.extend([f"{source_path}/", f"myminio/{bucket}/{prefix}"])
                
                # ì—…ë¡œë“œ ì‹¤í–‰
                progress_bar = st.progress(0, text="ì—…ë¡œë“œ ì¤€ë¹„ ì¤‘...")
                log_area = st.empty()
                
                try:
                    import subprocess
                    process = subprocess.Popen(
                        mc_args,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=True,
                        bufsize=1
                    )
                    
                    output_lines = []
                    uploaded_count = 0
                    
                    for line in process.stdout:
                        output_lines.append(line.strip())
                        if len(output_lines) > 10:
                            output_lines = output_lines[-10:]
                        
                        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (íŒŒì¼ëª…ì´ ì¶œë ¥ë  ë•Œë§ˆë‹¤)
                        if line.strip() and not line.startswith("mc:"):
                            uploaded_count += 1
                            progress = min(uploaded_count / max(file_count, 1), 1.0)
                            progress_bar.progress(progress, text=f"ì—…ë¡œë“œ ì¤‘... {uploaded_count}/{file_count}")
                        
                        log_area.code("\n".join(output_lines), language="text")
                    
                    process.wait()
                    
                    if process.returncode == 0:
                        progress_bar.progress(1.0, text="âœ… ì—…ë¡œë“œ ì™„ë£Œ!")
                        st.success(f"âœ… {file_count}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ!")
                        
                        # ìë™ ì¸ë±ì‹± ì‹¤í–‰
                        with st.spinner("ğŸ”„ ì§€ë„ ë¸Œë¼ìš°ì €ìš© ì¸ë±ì‹± ì¤‘..."):
                            idx_cmd = [
                                "python", "-m", "src.indexer.metadata_extractor",
                                "--bucket", bucket,
                                "--prefix", prefix
                            ]
                            idx_result = subprocess.run(idx_cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True)
                            if idx_result.returncode == 0:
                                st.success("ğŸ—ºï¸ ì¸ë±ì‹± ì™„ë£Œ! ì§€ë„ ë¸Œë¼ìš°ì € íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                            else:
                                st.warning("âš ï¸ ì¸ë±ì‹± ì‹¤íŒ¨ (ìˆ˜ë™ìœ¼ë¡œ ì§€ë„ ë¸Œë¼ìš°ì €ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”)")
                    else:
                        st.error("âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
                        
                except FileNotFoundError:
                    st.error("âŒ mc CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ `./scripts/setup_minio_cli.sh` ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜: {e}")
        
        st.markdown("---")
        st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
        st.caption("MinIO ë²„í‚·ì˜ ë°ì´í„°ë¥¼ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.")
        
        # ë²„í‚· ì„ íƒ (í¼ ì™¸ë¶€)
        dl_bucket = st.selectbox("ğŸª£ ë²„í‚· ì„ íƒ", ["raw-data", "raw-data-nvs", "processed-data", "mlflow-artifacts"], key="dl_bucket")
        
        # ì„ íƒëœ ë²„í‚·ì˜ í´ë” ëª©ë¡ ì¡°íšŒ
        try:
            s3 = get_minio_client()
            paginator = s3.get_paginator("list_objects_v2")
            folders = set()
            for page in paginator.paginate(Bucket=dl_bucket):
                for obj in page.get("Contents", []):
                    key = obj["Key"]
                    # ëª¨ë“  í´ë” ê²½ë¡œ ì¶”ì¶œ (ì¤‘ì²© í¬í•¨)
                    parts = key.split("/")
                    for i in range(1, len(parts)):
                        folder_path = "/".join(parts[:i]) + "/"
                        # thumbnails í´ë” ì œì™¸
                        if not folder_path.startswith("thumbnails"):
                            folders.add(folder_path)
            folder_list = sorted(list(folders))
        except:
            folder_list = []
        
        with st.form("download_form"):
            if folder_list:
                dl_prefix = st.selectbox("ğŸ“‚ ë‹¤ìš´ë¡œë“œí•  í´ë”", folder_list, key="dl_prefix")
            else:
                dl_prefix = st.text_input("ğŸ“‚ ë²„í‚· ë‚´ ê²½ë¡œ", placeholder="project/output/", key="dl_prefix_text")
            
            dl_local = st.text_input("ğŸ’¾ ë¡œì»¬ ì €ì¥ ê²½ë¡œ", placeholder="/workspace/downloads/", key="dl_local",
                                     help="ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ì„ ì €ì¥í•  ê²½ë¡œ (ì»¨í…Œì´ë„ˆ ê¸°ì¤€)")
            
            download_btn = st.form_submit_button("ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰", use_container_width=True, type="primary")
        
        if download_btn and dl_prefix and dl_local:
            # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
            mc_args = ["mc", "mirror", f"myminio/{dl_bucket}/{dl_prefix}", dl_local]
            
            progress_bar = st.progress(0, text="ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì¤‘...")
            log_area = st.empty()
            
            try:
                # ëŒ€ìƒ í´ë” ìƒì„±
                Path(dl_local).mkdir(parents=True, exist_ok=True)
                
                process = subprocess.Popen(
                    mc_args,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    text=True,
                    bufsize=1
                )
                
                output_lines = []
                download_count = 0
                
                for line in process.stdout:
                    output_lines.append(line.strip())
                    if len(output_lines) > 10:
                        output_lines = output_lines[-10:]
                    
                    if line.strip() and not line.startswith("mc:"):
                        download_count += 1
                        progress_bar.progress(min(download_count / 100, 0.99), text=f"ë‹¤ìš´ë¡œë“œ ì¤‘... {download_count}ê°œ íŒŒì¼")
                    
                    log_area.code("\n".join(output_lines), language="text")
                
                process.wait()
                
                if process.returncode == 0:
                    progress_bar.progress(1.0, text="âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                    st.success(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {dl_local}")
                else:
                    st.error("âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
                    
            except FileNotFoundError:
                st.error("âŒ mc CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")
    
    with col2:
        st.subheader("ğŸ“‹ MinIO ë°ì´í„° ëª©ë¡")
        
        buckets = list_minio_buckets()
        if buckets:
            selected_bucket = st.selectbox("ë²„í‚· ì„ íƒ", buckets)
            prefix_filter = st.text_input("Prefix í•„í„°", placeholder="project/")
            
            if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", key="refresh_minio"):
                st.rerun()
            
            objects = list_minio_objects(selected_bucket, prefix_filter)
            if objects:
                df = pd.DataFrame(objects)
                st.dataframe(df, use_container_width=True, height=300)
                st.info(f"ì´ {len(objects)}ê°œ ê°ì²´")
                
                st.markdown("---")
                st.subheader("ğŸ“¥ ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì„ì‹œ ë§í¬)")
                
                # íŒŒì¼ ì„ íƒìš© selectbox
                file_keys = [obj["Key"] for obj in objects]
                selected_file = st.selectbox("ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ ì„ íƒ", file_keys)
                
                if st.button("ğŸ”— ì„ì‹œ ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±", use_container_width=True):
                    tmp_url = get_presigned_url(selected_bucket, selected_file)
                    if tmp_url:
                        st.success(f"âœ… ë§í¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤ (7ì¼ê°„ ìœ íš¨)")
                        st.code(tmp_url)
                        st.link_button("ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸° / ë‹¤ìš´ë¡œë“œ", tmp_url, use_container_width=True)
            else:
                st.info("ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")


# ============================================
# Tab 2: ğŸ“ ì§€ë„ ë¸Œë¼ìš°ì €
# ============================================
elif selected_tab == "ğŸ“ ì§€ë„ ë¸Œë¼ìš°ì €":
    st.markdown('<h1 class="main-header">ğŸ“ ì§€ë„ ë¸Œë¼ìš°ì €</h1>', unsafe_allow_html=True)
    
    # STAC API ì„¤ì •
    STAC_API_URL = os.getenv("STAC_API_URL", "http://localhost:8080")
    TITILER_URL = os.getenv("TITILER_URL", "http://localhost:8082")
    
    def get_stac_collections():
        """STAC ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ"""
        try:
            import requests
            response = requests.get(f"{STAC_API_URL}/collections", timeout=5)
            if response.status_code == 200:
                return [c["id"] for c in response.json().get("collections", [])]
        except:
            pass
        return []
    
    def search_stac_items(collections=None, limit=500):
        """STAC ê²€ìƒ‰"""
        try:
            import requests
            params = {"limit": limit}
            if collections:
                params["collections"] = collections
            response = requests.post(f"{STAC_API_URL}/search", json=params, timeout=30)
            if response.status_code == 200:
                return response.json().get("features", [])
        except:
            pass
        return []
    
    def get_stac_item_count(collections=None):
        """STAC ì•„ì´í…œ ê°œìˆ˜"""
        items = search_stac_items(collections, limit=1000)
        return len(items)
    
    # ë ˆê±°ì‹œ DB ì—°ê²° í•¨ìˆ˜
    def get_db_connection():
        import psycopg2
        return psycopg2.connect(
            host=os.getenv("POSTGRES_HOST", "localhost"),
            port=os.getenv("POSTGRES_PORT", "5432"),
            user=os.getenv("POSTGRES_USER", "mlflow"),
            password=os.getenv("POSTGRES_PASSWORD", "mlflow123"),
            dbname=os.getenv("POSTGRES_DB", "mlflow"),
        )
    
    # STAC API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
    stac_available = len(get_stac_collections()) > 0
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.subheader("ğŸ” í•„í„°")
        
        if stac_available:
            # STAC ëª¨ë“œ: ì»¬ë ‰ì…˜ í•„í„°
            collections = get_stac_collections()
            collection_filter = st.selectbox("ğŸ“ ì»¬ë ‰ì…˜", ["ì „ì²´"] + collections, key="map_collection_filter")
            
            # ë°ì´í„° ìœ í˜• (ì»¬ë ‰ì…˜ ê¸°ë°˜ ìë™ ì„¤ì •)
            if collection_filter == "drone-photos":
                data_type_filter = "ì‚¬ì§„ (photo)"
            elif collection_filter == "orthoimages":
                data_type_filter = "ì •ì‚¬ì˜ìƒ (ortho)"
            else:
                data_type_filter = st.selectbox("ğŸ“· ë°ì´í„° ìœ í˜•", ["ì „ì²´", "ì‚¬ì§„ (photo)", "ì •ì‚¬ì˜ìƒ (ortho)"], key="map_type_filter")
            
            bucket_filter = "ì „ì²´"  # STAC ëª¨ë“œì—ì„œëŠ” ì‚¬ìš© ì•ˆ í•¨
            folder_filter = ""
        else:
            # ë ˆê±°ì‹œ ëª¨ë“œ
            st.info("âš ï¸ STAC API ë¯¸ì—°ê²° - ë ˆê±°ì‹œ ëª¨ë“œ")
            collection_filter = "ì „ì²´"
            
            # ë²„í‚· í•„í„°
            try:
                conn = get_db_connection()
                cur = conn.cursor()
                cur.execute("SELECT DISTINCT bucket FROM image_metadata ORDER BY bucket")
                db_buckets = [row[0] for row in cur.fetchall()]
                cur.close()
                conn.close()
            except:
                db_buckets = []
            
            bucket_filter = st.selectbox("ğŸ“¦ ë²„í‚·", ["ì „ì²´"] + db_buckets, key="map_bucket_filter")
            folder_filter = ""
            data_type_filter = st.selectbox("ğŸ“· ë°ì´í„° ìœ í˜•", ["ì „ì²´", "ì‚¬ì§„ (photo)", "ì •ì‚¬ì˜ìƒ (ortho)"])
        
        st.markdown("---")
        
        # í†µê³„ ì¡°íšŒ
        if stac_available:
            # STAC ëª¨ë“œ
            selected_collections = None
            if collection_filter != "ì „ì²´":
                selected_collections = [collection_filter]
            elif data_type_filter == "ì‚¬ì§„ (photo)":
                selected_collections = ["drone-photos"]
            elif data_type_filter == "ì •ì‚¬ì˜ìƒ (ortho)":
                selected_collections = ["orthoimages"]
            
            filtered_count = get_stac_item_count(selected_collections)
            total_count = get_stac_item_count()
            st.metric("í‘œì‹œ ë°ì´í„°", f"{filtered_count}ê°œ", f"ì „ì²´ {total_count}ê°œ ì¤‘")
        else:
            # ë ˆê±°ì‹œ ëª¨ë“œ
            try:
                conn = get_db_connection()
                cur = conn.cursor()
                
                where_clauses = ["1=1"]
                if bucket_filter != "ì „ì²´":
                    where_clauses.append(f"bucket = '{bucket_filter}'")
                if data_type_filter == "ì‚¬ì§„ (photo)":
                    where_clauses.append("data_type = 'photo'")
                elif data_type_filter == "ì •ì‚¬ì˜ìƒ (ortho)":
                    where_clauses.append("data_type = 'ortho'")
                
                where_sql = " AND ".join(where_clauses)
                
                cur.execute(f"SELECT COUNT(*) FROM image_metadata WHERE {where_sql}")
                filtered_count = cur.fetchone()[0]
                cur.execute("SELECT COUNT(*) FROM image_metadata")
                total_count = cur.fetchone()[0]
                cur.close()
                conn.close()
                
                st.metric("í‘œì‹œ ë°ì´í„°", f"{filtered_count}ê°œ", f"ì „ì²´ {total_count}ê°œ ì¤‘")
            except Exception as e:
                st.warning(f"DB ì˜¤ë¥˜: {e}")
                filtered_count = 0
        
        st.markdown("---")
        
        # ì¸ë±ì‹± ì„¹ì…˜ (ì ‘í˜)
        with st.expander("ğŸ“Š ì‹ ê·œ ë°ì´í„° ì¸ë±ì‹±"):
            buckets = list_minio_buckets()
            if buckets:
                idx_bucket = st.selectbox("ë²„í‚·", buckets, key="idx_bucket")
                idx_prefix = st.text_input("Prefix", key="idx_prefix")
                
                if st.button("ğŸ”„ ì¸ë±ì‹± ì‹¤í–‰", use_container_width=True):
                    with st.spinner("ì¸ë±ì‹± ì¤‘..."):
                        import subprocess
                        cmd = [
                            "python", "-m", "src.indexer.metadata_extractor",
                            "--bucket", idx_bucket,
                            "--prefix", idx_prefix
                        ]
                        result = subprocess.run(cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True)
                        
                        # ê²°ê³¼ íŒŒì‹±: ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ ìˆ˜ í™•ì¸
                        output = result.stdout + result.stderr
                        new_count = output.count("âœ… ì¸ë±ì‹± ì™„ë£Œ:")
                        skip_count = output.count("ì´ë¯¸ ì¸ë±ì‹±ë¨") if "ì´ë¯¸ ì¸ë±ì‹±ë¨" in output else 0
                        
                        if result.returncode == 0:
                            st.success(f"âœ… ì™„ë£Œ! (ì‹ ê·œ: {new_count}ê°œ)")
                            st.rerun()
                        else:
                            st.error("âŒ ì‹¤íŒ¨")
                            st.code(result.stderr[-500:] if result.stderr else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
    
    with col1:
        st.subheader("ğŸ—ºï¸ ì§€ë„")
        
        try:
            import folium
            from streamlit_folium import st_folium
            import json
            
            # ë°ì´í„° ì¡°íšŒ
            all_coords = []
            photos = []
            orthos = []
            
            if stac_available:
                # STAC ëª¨ë“œ: API ê²€ìƒ‰
                search_collections = None
                if collection_filter != "ì „ì²´":
                    search_collections = [collection_filter]
                elif data_type_filter == "ì‚¬ì§„ (photo)":
                    search_collections = ["drone-photos"]
                elif data_type_filter == "ì •ì‚¬ì˜ìƒ (ortho)":
                    search_collections = ["orthoimages"]
                
                items = search_stac_items(collections=search_collections, limit=500)
                
                for item in items:
                    geom = item.get("geometry", {})
                    props = item.get("properties", {})
                    assets = item.get("assets", {})
                    
                    # thumbnail hrefì—ì„œ key ì¶”ì¶œ (http://minio:9000/bucket/key í˜•íƒœ)
                    thumb_href = assets.get("thumbnail", {}).get("href", "")
                    thumb_key = ""
                    if thumb_href and "/thumbnails/" in thumb_href:
                        try:
                            # http://minio:9000/raw-data/thumbnails/xxx.jpg -> thumbnails/xxx.jpg
                            parts = thumb_href.split("/")
                            bucket_idx = parts.index("raw-data") if "raw-data" in parts else -1
                            if bucket_idx >= 0:
                                thumb_key = "/".join(parts[bucket_idx + 1:])
                        except:
                            pass
                    
                    if geom.get("type") == "Point":
                        lon, lat = geom["coordinates"]
                        all_coords.append((lat, lon))
                        photos.append({
                            "id": item["id"],
                            "filename": props.get("filename", item["id"]),
                            "bucket": props.get("bucket", "raw-data"),
                            "key": props.get("object_key", ""),
                            "lon": lon,
                            "lat": lat,
                            "file_size": props.get("file_size", 0),
                            "thumb_key": thumb_key or props.get("thumbnail_key", ""),
                        })
                    elif geom.get("type") == "Polygon":
                        bbox = item.get("bbox", [])
                        if len(bbox) >= 4:
                            center_lon = (bbox[0] + bbox[2]) / 2
                            center_lat = (bbox[1] + bbox[3]) / 2
                            all_coords.append((center_lat, center_lon))
                        orthos.append({
                            "id": item["id"],
                            "filename": props.get("filename", item["id"]),
                            "bucket": props.get("bucket", "raw-data"),
                            "key": props.get("object_key", ""),
                            "geometry": geom,
                            "resolution": props.get("proj:resolution", [None])[0] if isinstance(props.get("proj:resolution"), list) else props.get("proj:resolution"),
                            "file_size": props.get("file_size", 0),
                            "thumb_key": thumb_key or props.get("thumbnail_key", ""),
                        })
            else:
                # ë ˆê±°ì‹œ DB ëª¨ë“œ
                try:
                    conn = get_db_connection()
                    cur = conn.cursor()
                    
                    where_clauses = ["1=1"]
                    if bucket_filter != "ì „ì²´":
                        where_clauses.append(f"bucket = '{bucket_filter}'")
                    if data_type_filter == "ì‚¬ì§„ (photo)":
                        where_clauses.append("data_type = 'photo'")
                    elif data_type_filter == "ì •ì‚¬ì˜ìƒ (ortho)":
                        where_clauses.append("data_type = 'ortho'")
                    where_sql = " AND ".join(where_clauses)
                    
                    cur.execute(f"""
                        SELECT id, filename, bucket, object_key, 
                               ST_X(location) as lon, ST_Y(location) as lat,
                               thumbnail_key, file_size
                        FROM image_metadata 
                        WHERE location IS NOT NULL AND {where_sql}
                        LIMIT 500
                    """)
                    for row in cur.fetchall():
                        all_coords.append((row[5], row[4]))
                        photos.append({
                            "id": row[0],
                            "filename": row[1],
                            "bucket": row[2],
                            "key": row[3],
                            "lon": row[4],
                            "lat": row[5],
                            "file_size": row[7] or 0,
                            "thumb_key": row[6],
                        })
                    
                    cur.execute(f"""
                        SELECT id, filename, bucket, object_key,
                               ST_AsGeoJSON(extent) as extent_geojson,
                               ST_X(ST_Centroid(extent)) as clon, ST_Y(ST_Centroid(extent)) as clat,
                               resolution, file_size, thumbnail_key
                        FROM image_metadata 
                        WHERE extent IS NOT NULL AND {where_sql}
                        LIMIT 100
                    """)
                    for row in cur.fetchall():
                        if row[5] and row[6]:
                            all_coords.append((row[6], row[5]))
                        orthos.append({
                            "id": row[0],
                            "filename": row[1],
                            "bucket": row[2],
                            "key": row[3],
                            "geometry": json.loads(row[4]),
                            "resolution": row[7],
                            "file_size": row[8] or 0,
                            "thumb_key": row[9],
                        })
                    
                    cur.close()
                    conn.close()
                except Exception as e:
                    st.warning(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ì§€ë„ ì¤‘ì‹¬ ë° ì¤Œ ê³„ì‚° (ë°ì´í„° ë²”ìœ„ ê¸°ë°˜)
            if all_coords:
                lats = [c[0] for c in all_coords]
                lons = [c[1] for c in all_coords]
                center_lat = sum(lats) / len(lats)
                center_lon = sum(lons) / len(lons)
                
                # ë²”ìœ„ì— ë§ëŠ” ì¤Œ ë ˆë²¨ ê³„ì‚°
                lat_range = max(lats) - min(lats)
                lon_range = max(lons) - min(lons)
                max_range = max(lat_range, lon_range)
                
                if max_range < 0.01:
                    zoom = 15
                elif max_range < 0.1:
                    zoom = 12
                elif max_range < 1:
                    zoom = 10
                elif max_range < 5:
                    zoom = 8
                else:
                    zoom = 6
            else:
                center_lat, center_lon, zoom = 36.5, 127.5, 7  # ê¸°ë³¸ê°’ (ëŒ€í•œë¯¼êµ­)
            
            m = folium.Map(location=[center_lat, center_lon], zoom_start=zoom)
            
            # ì‚¬ì§„ ë§ˆì»¤ ì¶”ê°€
            for photo in photos:
                # presigned URL ìƒì„± (STAC/ë ˆê±°ì‹œ ëª¨ë‘ ë™ì¼)
                try:
                    original_url = get_presigned_url(photo["bucket"], photo["key"], expires_in=3600) if photo.get("key") else ""
                except:
                    original_url = ""
                
                # ì¸ë„¤ì¼ URL (thumb_keyê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸)
                thumb_key = photo.get("thumb_key") or photo.get("key", "")
                try:
                    thumb_url = get_presigned_url(photo["bucket"], thumb_key, expires_in=3600) if thumb_key else ""
                except:
                    thumb_url = ""
                
                thumb_html = ""
                if thumb_url:
                    if original_url:
                        thumb_html = f'<a href="{original_url}" target="_blank"><img src="{thumb_url}" style="max-width:200px;max-height:150px;margin-bottom:8px;border-radius:4px;cursor:pointer;" title="í´ë¦­í•˜ë©´ ì›ë³¸ ì—´ê¸°"></a><br>'
                    else:
                        thumb_html = f'<img src="{thumb_url}" style="max-width:200px;max-height:150px;margin-bottom:8px;border-radius:4px;"><br>'
                
                size_mb = photo["file_size"] / (1024 * 1024)
                popup_html = f"""
                {thumb_html}
                <b>{photo['filename']}</b><br>
                ğŸ“¦ {photo['bucket']}<br>
                ğŸ’¾ {size_mb:.1f} MB
                """
                folium.Marker(
                    location=[photo["lat"], photo["lon"]],
                    popup=folium.Popup(popup_html, max_width=300),
                    icon=folium.Icon(color="blue", icon="camera", prefix="fa")
                ).add_to(m)
            
            # ì •ì‚¬ì˜ìƒ í´ë¦¬ê³¤ ì¶”ê°€
            for ortho in orthos:
                # presigned URL ìƒì„± (STAC/ë ˆê±°ì‹œ ëª¨ë‘ ë™ì¼)
                try:
                    original_url = get_presigned_url(ortho["bucket"], ortho["key"], expires_in=3600) if ortho.get("key") else ""
                except:
                    original_url = ""
                
                # ì¸ë„¤ì¼ URL (thumb_keyê°€ ìˆìœ¼ë©´ ì‚¬ìš©)
                thumb_key = ortho.get("thumb_key", "")
                try:
                    thumb_url = get_presigned_url(ortho["bucket"], thumb_key, expires_in=3600) if thumb_key else ""
                except:
                    thumb_url = ""
                
                thumb_html = ""
                if thumb_url:
                    if original_url:
                        thumb_html = f'<a href="{original_url}" target="_blank"><img src="{thumb_url}" style="max-width:200px;max-height:150px;margin-bottom:8px;border-radius:4px;cursor:pointer;" title="í´ë¦­í•˜ë©´ ë‹¤ìš´ë¡œë“œ"></a><br>'
                    else:
                        thumb_html = f'<img src="{thumb_url}" style="max-width:200px;max-height:150px;margin-bottom:8px;border-radius:4px;"><br>'
                
                res_str = f"{ortho['resolution']:.2f}m" if ortho.get("resolution") else "N/A"
                popup_html = f"""
                {thumb_html}
                <b>{ortho['filename']}</b><br>
                ğŸ“¦ {ortho['bucket']}<br>
                ğŸ“ í•´ìƒë„: {res_str}<br>
                ğŸ’¾ {ortho['file_size'] / (1024*1024):.1f} MB
                """
                folium.GeoJson(
                    ortho["geometry"],
                    style_function=lambda x: {
                        "fillColor": "#3388ff",
                        "color": "#3388ff",
                        "weight": 2,
                        "fillOpacity": 0.3
                    },
                    popup=folium.Popup(popup_html, max_width=300)
                ).add_to(m)
            
            # ì§€ë„ í‘œì‹œ
            st_folium(m, width=None, height=600, returned_objects=[])
            
            if not photos and not orthos:
                st.info("ğŸ“­ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥¸ìª½ íŒ¨ë„ì—ì„œ ì¸ë±ì‹±ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            
        except ImportError:
            st.error("ğŸ“¦ folium ë˜ëŠ” streamlit-foliumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# ============================================
# Tab 3: Training Lab
# ============================================
elif selected_tab == "ğŸ”¬ Training Lab":
    st.markdown('<h1 class="main-header">ğŸ”¬ Training Lab</h1>', unsafe_allow_html=True)
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "training_process" not in st.session_state:
        st.session_state.training_process = None
    if "training_logs" not in st.session_state:
        st.session_state.training_logs = []
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("âš™ï¸ í•™ìŠµ ì„¤ì •")
        
        task_type = st.selectbox(
            "Task Type",
            ["Change Detection", "Novel View Synthesis (3DGS)"]
        )
        
        config_files = get_config_files()
        if task_type == "Change Detection":
            default_config = "train_cd.yaml" if "train_cd.yaml" in config_files else config_files[0]
        else:
            default_config = "train_nvs.yaml" if "train_nvs.yaml" in config_files else config_files[0]
        
        selected_config = st.selectbox("Config íŒŒì¼", config_files, index=config_files.index(default_config) if default_config in config_files else 0)
        
        # ì„¤ì • ë¡œë“œ ë° í¸ì§‘
        if selected_config:
            config = load_config(selected_config)
            
            st.markdown("##### ğŸ“ ë°ì´í„° ê²½ë¡œ ì„¤ì •")
            data_dirs = get_data_directories()
            
            if task_type == "Change Detection":
                current_data_dir = config.get("data", {}).get("local", {}).get("root_dir", "./data/change_detection")
                # í´ë” ì´ë¦„ë§Œ ì¶”ì¶œ (./data/xxx -> xxx)
                default_data_folder = Path(current_data_dir).name
                
                selected_data_folder = st.selectbox(
                    "í•™ìŠµ ë°ì´í„° í´ë” (./data/)",
                    data_dirs,
                    index=data_dirs.index(default_data_folder) if default_data_folder in data_dirs else 0
                )
                custom_data_path = st.text_input("ìƒì„¸ ê²½ë¡œ (ì§ì ‘ ì…ë ¥)", value=f"./data/{selected_data_folder}")
                
                st.markdown("##### ğŸ§  í•™ìŠµ íŒŒë¼ë¯¸í„° ìˆ˜ì •")
                epochs = st.number_input("Epochs", value=config.get("training", {}).get("epochs", 50), min_value=1)
                batch_size = st.number_input("Batch Size", value=config.get("training", {}).get("batch_size", 8), min_value=1)
                lr = st.number_input("Learning Rate", value=config.get("training", {}).get("optimizer", {}).get("lr", 0.001), format="%.5f")
                
                overrides = f"data.local.root_dir={custom_data_path} training.epochs={epochs} training.batch_size={batch_size} training.optimizer.lr={lr}"
                script = "src/training/train_cd.py"
            else:
                current_data_path = config.get("data", {}).get("source_path", "./data/nvs_project")
                default_data_folder = Path(current_data_path).name
                
                selected_data_folder = st.selectbox(
                    "í•™ìŠµ ë°ì´í„° í´ë” (./data/)",
                    data_dirs,
                    index=data_dirs.index(default_data_folder) if default_data_folder in data_dirs else 0
                )
                custom_data_path = st.text_input("ìƒì„¸ ê²½ë¡œ (ì§ì ‘ ì…ë ¥)", value=f"./data/{selected_data_folder}")
                
                st.markdown("##### ğŸ§  í•™ìŠµ íŒŒë¼ë¯¸í„° ìˆ˜ì •")
                iterations = st.number_input("Iterations", value=config.get("training", {}).get("iterations", 30000), min_value=100, step=1000)
                sh_degree = st.number_input("SH Degree", value=config.get("model", {}).get("sh_degree", 3), min_value=0, max_value=3)
                
                overrides = f"data.source_path={custom_data_path} training.iterations={iterations} model.sh_degree={sh_degree}"
                script = "src/training/train_nvs.py"
        
        st.markdown("---")
        
        # í•™ìŠµ ì‹¤í–‰ ë²„íŠ¼
        start_btn = st.button("ğŸš€ í•™ìŠµ ì‹œì‘", use_container_width=True, type="primary")
        stop_btn = st.button("â¹ï¸ í•™ìŠµ ì¤‘ì§€", use_container_width=True)
        
        if start_btn:
            cmd = ["python", script, "--config", f"configs/{selected_config}", "-o"] + overrides.split()
            st.session_state.training_process = run_command_async(cmd, str(PROJECT_ROOT))
            st.session_state.training_logs = []
            st.success("í•™ìŠµì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        if stop_btn and st.session_state.training_process:
            st.session_state.training_process.terminate()
            st.session_state.training_process = None
            st.warning("í•™ìŠµì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    with col2:
        st.subheader("ğŸ“Š ì‹¤í–‰ ë¡œê·¸")
        
        log_container = st.empty()
        status_container = st.empty()
        
        # í”„ë¡œì„¸ìŠ¤ ìƒíƒœ í™•ì¸ ë° ë¡œê·¸ ì—…ë°ì´íŠ¸
        if st.session_state.training_process:
            proc = st.session_state.training_process
            
            # Non-blocking read
            import select
            if proc.poll() is None:
                status_container.markdown('<span class="status-running">ğŸ”„ í•™ìŠµ ì§„í–‰ ì¤‘...</span>', unsafe_allow_html=True)
                
                # ë¡œê·¸ ì½ê¸° (non-blocking)
                try:
                    while True:
                        line = proc.stdout.readline()
                        if line:
                            st.session_state.training_logs.append(line.strip())
                            # ìµœê·¼ 100ì¤„ë§Œ ìœ ì§€
                            if len(st.session_state.training_logs) > 100:
                                st.session_state.training_logs = st.session_state.training_logs[-100:]
                        else:
                            break
                except:
                    pass
            else:
                if proc.returncode == 0:
                    status_container.markdown('<span class="status-success">âœ… í•™ìŠµ ì™„ë£Œ!</span>', unsafe_allow_html=True)
                else:
                    status_container.markdown('<span class="status-error">âŒ í•™ìŠµ ì‹¤íŒ¨</span>', unsafe_allow_html=True)
                st.session_state.training_process = None
        
        # ë¡œê·¸ í‘œì‹œ
        if st.session_state.training_logs:
            log_text = "\n".join(st.session_state.training_logs[-50:])
            log_container.code(log_text, language="bash")
        else:
            log_container.info("í•™ìŠµì„ ì‹œì‘í•˜ë©´ ë¡œê·¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
        
        # ìë™ ìƒˆë¡œê³ ì¹¨
        if st.session_state.training_process:
            time.sleep(1)
            st.rerun()


# ============================================
# Tab 3: Model Registry
# ============================================
elif selected_tab == "ğŸ“¦ Model Registry":
    st.markdown('<h1 class="main-header">ğŸ“¦ Model Registry</h1>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“Š ìµœê·¼ í•™ìŠµ ê²°ê³¼")
        
        experiment_filter = st.selectbox(
            "ì‹¤í—˜ í•„í„°",
            ["ì „ì²´", "satellite-change-detection", "nvs-gaussian-splatting"]
        )
        
        exp_name = None if experiment_filter == "ì „ì²´" else experiment_filter
        runs_df = get_mlflow_runs(exp_name, max_results=20)
        
        if not runs_df.empty:
            # í‘œì‹œìš© ì»¬ëŸ¼ë§Œ ì„ íƒ
            display_df = runs_df[["Run ID", "Name", "Status", "PSNR", "IoU", "Duration"]]
            st.dataframe(display_df, use_container_width=True, height=400)
            
            # ì„ íƒí•œ Runì˜ ìƒì„¸ ì •ë³´
            selected_run = st.selectbox("ìƒì„¸ ë³´ê¸°", runs_df["Full Run ID"].tolist())
            if selected_run:
                st.markdown(f"**Full Run ID:** `{selected_run}`")
                st.link_button(
                    "ğŸ”— MLflowì—ì„œ ë³´ê¸°",
                    f"http://{st.session_state.public_ip}:{MLFLOW_PORT}/#/experiments/0/runs/{selected_run}",
                    use_container_width=True
                )
        else:
            st.info("í•™ìŠµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.subheader("ğŸ”— MLflow UI")
        
        # ì„¸ì…˜ ì´ˆê¸°í™”ëœ IPë¥¼ ì‚¬ìš© (í•˜ë“œì½”ë”©ëœ PUBLIC_IP ëŒ€ì‹ )
        mlflow_url = f"http://{st.session_state.public_ip}:{MLFLOW_PORT}"
        
        st.link_button(
            "ğŸŒ MLflow UI ì—´ê¸°",
            mlflow_url,
            use_container_width=True,
            type="primary"
        )
        
        st.markdown("---")
        
        st.markdown("##### ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½")
        
        if not runs_df.empty:
            # PSNR í†µê³„
            psnr_values = runs_df[runs_df["PSNR"] != "-"]["PSNR"].astype(float)
            if len(psnr_values) > 0:
                st.metric("í‰ê·  PSNR", f"{psnr_values.mean():.2f} dB")
                st.metric("ìµœê³  PSNR", f"{psnr_values.max():.2f} dB")
            
            # IoU í†µê³„
            iou_values = runs_df[runs_df["IoU"] != "-"]["IoU"].astype(float)
            if len(iou_values) > 0:
                st.metric("í‰ê·  IoU", f"{iou_values.mean():.4f}")
                st.metric("ìµœê³  IoU", f"{iou_values.max():.4f}")


# ============================================
# Tab 4: Inference
# ============================================
elif selected_tab == "ğŸ”® Inference":
    st.markdown('<h1 class="main-header">ğŸ”® Inference</h1>', unsafe_allow_html=True)
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "inference_result" not in st.session_state:
        st.session_state.inference_result = None
    
    task_type = st.radio(
        "Task Type",
        ["Change Detection", "Novel View Synthesis"],
        horizontal=True
    )
    
    st.markdown("---")
    
    if task_type == "Change Detection":
        st.subheader("ğŸ›°ï¸ Change Detection Inference")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### ëª¨ë¸ ì„ íƒ")
            model_source = st.radio("ëª¨ë¸ ì†ŒìŠ¤", ["ì²´í¬í¬ì¸íŠ¸ íŒŒì¼", "MLflow Run ID"], horizontal=True)
            
            if model_source == "ì²´í¬í¬ì¸íŠ¸ íŒŒì¼":
                checkpoint = st.text_input("ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ", value="checkpoints/final_model.pth")
            else:
                runs_df = get_mlflow_runs("satellite-change-detection", 10)
                if not runs_df.empty:
                    run_id = st.selectbox("Run ì„ íƒ", runs_df["Full Run ID"].tolist())
                else:
                    run_id = st.text_input("Run ID ì…ë ¥")
            
            st.markdown("##### ì…ë ¥ ì´ë¯¸ì§€")
            pre_image = st.file_uploader("Pre ì´ë¯¸ì§€ (GeoTIFF)", type=["tif", "tiff"])
            post_image = st.file_uploader("Post ì´ë¯¸ì§€ (GeoTIFF)", type=["tif", "tiff"])
        
        with col2:
            st.markdown("##### ê²°ê³¼")
            
            if st.button("ğŸ”® ì¶”ë¡  ì‹¤í–‰", use_container_width=True, type="primary"):
                if pre_image and post_image:
                    with st.spinner("ì¶”ë¡  ì¤‘..."):
                        # ì„ì‹œ íŒŒì¼ ì €ì¥
                        import tempfile
                        with tempfile.TemporaryDirectory() as tmpdir:
                            pre_path = Path(tmpdir) / "pre.tif"
                            post_path = Path(tmpdir) / "post.tif"
                            output_dir = Path(tmpdir) / "output"
                            
                            pre_path.write_bytes(pre_image.read())
                            post_path.write_bytes(post_image.read())
                            
                            # ì¶”ë¡  ì‹¤í–‰
                            if model_source == "ì²´í¬í¬ì¸íŠ¸ íŒŒì¼":
                                cmd = ["python", "src/inference/predict_cd.py",
                                       "--checkpoint", checkpoint,
                                       "--pre", str(pre_path),
                                       "--post", str(post_path),
                                       "-o", str(output_dir)]
                            else:
                                cmd = ["python", "src/inference/predict_cd.py",
                                       "--run-id", run_id,
                                       "--pre", str(pre_path),
                                       "--post", str(post_path),
                                       "-o", str(output_dir)]
                            
                            result = subprocess.run(cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True)
                            
                            if result.returncode == 0:
                                viz_path = output_dir / "visualization.png"
                                if viz_path.exists():
                                    st.image(str(viz_path), caption="ì¶”ë¡  ê²°ê³¼", use_container_width=True)
                                    st.success("âœ… ì¶”ë¡  ì™„ë£Œ!")
                                else:
                                    st.warning("ì‹œê°í™” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.error("âŒ ì¶”ë¡  ì‹¤íŒ¨")
                                st.code(result.stderr)
                else:
                    st.warning("Pre/Post ì´ë¯¸ì§€ë¥¼ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    else:  # NVS
        st.subheader("ğŸ¬ Novel View Synthesis Rendering")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### ëª¨ë¸ ì„ íƒ")
            model_source = st.radio("ëª¨ë¸ ì†ŒìŠ¤", ["PLY ì²´í¬í¬ì¸íŠ¸", "MLflow Run ID"], horizontal=True, key="nvs_source")
            
            if model_source == "PLY ì²´í¬í¬ì¸íŠ¸":
                checkpoint = st.text_input("PLY ê²½ë¡œ", value="output/nvs/point_cloud.ply")
            else:
                runs_df = get_mlflow_runs("nvs-gaussian-splatting", 10)
                if not runs_df.empty:
                    run_id = st.selectbox("Run ì„ íƒ", runs_df["Full Run ID"].tolist(), key="nvs_run")
                else:
                    run_id = st.text_input("Run ID ì…ë ¥", key="nvs_run_input")
            
            st.markdown("##### ë Œë”ë§ ì„¤ì •")
            num_frames = st.slider("í”„ë ˆì„ ìˆ˜", 30, 240, 60)
            fps = st.slider("FPS", 15, 60, 30)
            resolution = st.selectbox("í•´ìƒë„", ["1280x720", "1920x1080", "640x480"])
            width, height = map(int, resolution.split("x"))
        
        with col2:
            st.markdown("##### ê²°ê³¼")
            
            if st.button("ğŸ¬ ë Œë”ë§ ì‹¤í–‰", use_container_width=True, type="primary"):
                with st.spinner("ë Œë”ë§ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                    output_dir = PROJECT_ROOT / "output" / "dashboard_render"
                    
                    # ì„œë¸Œí”„ë¡œì„¸ìŠ¤ í™˜ê²½ë³€ìˆ˜ì— PUBLIC_IP ì „ë‹¬
                    env = os.environ.copy()
                    env["PUBLIC_IP"] = st.session_state.public_ip
                    
                    if model_source == "PLY ì²´í¬í¬ì¸íŠ¸":
                        cmd = ["python", "src/inference/render_nvs.py",
                               "--checkpoint", checkpoint,
                               "--auto-orbit",
                               "--num-frames", str(num_frames),
                               "--fps", str(fps),
                               "--width", str(width),
                               "--height", str(height),
                               "-o", str(output_dir)]
                    else:
                        cmd = ["python", "src/inference/render_nvs.py",
                               "--run-id", run_id,
                               "--auto-orbit",
                               "--num-frames", str(num_frames),
                               "--fps", str(fps),
                               "--width", str(width),
                               "--height", str(height),
                               "-o", str(output_dir)]
                    
                    result = subprocess.run(cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True, timeout=300, env=env)
                    
                    if result.returncode == 0:
                        # ë¹„ë””ì˜¤ íŒŒì¼ ì°¾ê¸°
                        video_files = list(output_dir.glob("*.mp4"))
                        if video_files:
                            video_path = video_files[-1]
                            st.video(str(video_path))
                            st.success("âœ… ë Œë”ë§ ì™„ë£Œ!")
                            
                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            with open(video_path, "rb") as f:
                                st.download_button(
                                    "ğŸ“¥ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
                                    f.read(),
                                    file_name=video_path.name,
                                    mime="video/mp4"
                                )
                        else:
                            st.warning("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.error("âŒ ë Œë”ë§ ì‹¤íŒ¨")
                        st.code(result.stderr[-1000:] if len(result.stderr) > 1000 else result.stderr)


# ============================================
# í‘¸í„°
# ============================================
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #888; font-size: 0.8rem;'>
        ğŸš€ MLOps Standard Stack Dashboard | Built with Streamlit
    </div>
    """,
    unsafe_allow_html=True
)
