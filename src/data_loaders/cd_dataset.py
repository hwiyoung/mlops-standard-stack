"""
ë³€í™”íƒì§€ ë°ì´í„°ì…‹ ëª¨ë“ˆ
TorchGeo ê¸°ë°˜ + MinIO ìºì‹± ì§€ì›
"""

import os
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import rasterio
import torch
from rasterio.crs import CRS
from rasterio.transform import from_bounds
from torch.utils.data import DataLoader

try:
    from torchgeo.datasets import RasterDataset
    from torchgeo.samplers import RandomGeoSampler, GridGeoSampler
except ImportError:
    raise ImportError("torchgeoê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install torchgeo")


class ChangeDetectionPreDataset(RasterDataset):
    """ë³€í™” ì „(Pre) ì´ë¯¸ì§€ ë°ì´í„°ì…‹"""
    filename_glob = "*.tif"
    is_image = True
    separate_files = False


class ChangeDetectionPostDataset(RasterDataset):
    """ë³€í™” í›„(Post) ì´ë¯¸ì§€ ë°ì´í„°ì…‹"""
    filename_glob = "*.tif"
    is_image = True
    separate_files = False


class ChangeDetectionMaskDataset(RasterDataset):
    """ë³€í™” ë§ˆìŠ¤í¬ ë°ì´í„°ì…‹"""
    filename_glob = "*.tif"
    is_image = False
    separate_files = False


class ChangeDetectionDataModule:
    """
    ë³€í™”íƒì§€ ë°ì´í„° ëª¨ë“ˆ
    TorchGeo ë°ì´í„°ì…‹ê³¼ ìƒ˜í”ŒëŸ¬ë¥¼ ê´€ë¦¬
    """
    
    def __init__(
        self,
        data_dir: str,
        pre_dir: str = "pre",
        post_dir: str = "post",
        mask_dir: str = "mask",
        patch_size: int = 256,
        batch_size: int = 8,
        samples_per_epoch: int = 1000,
        num_workers: int = 4,
        crs: Optional[str] = None,
        res: Optional[float] = None,
    ):
        """
        Args:
            data_dir: ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬
            pre_dir: Pre ì´ë¯¸ì§€ ì„œë¸Œë””ë ‰í† ë¦¬
            post_dir: Post ì´ë¯¸ì§€ ì„œë¸Œë””ë ‰í† ë¦¬
            mask_dir: ë§ˆìŠ¤í¬ ì„œë¸Œë””ë ‰í† ë¦¬
            patch_size: íŒ¨ì¹˜ í¬ê¸°
            batch_size: ë°°ì¹˜ í¬ê¸°
            samples_per_epoch: ì—í­ë‹¹ ìƒ˜í”Œ ìˆ˜
            num_workers: DataLoader worker ìˆ˜
            crs: ì¢Œí‘œê³„ (Noneì´ë©´ ìë™)
            res: í•´ìƒë„ (Noneì´ë©´ ìë™)
        """
        self.data_dir = Path(data_dir)
        self.pre_path = self.data_dir / pre_dir
        self.post_path = self.data_dir / post_dir
        self.mask_path = self.data_dir / mask_dir
        
        self.patch_size = patch_size
        self.batch_size = batch_size
        self.samples_per_epoch = samples_per_epoch
        self.num_workers = num_workers
        self.crs = crs
        self.res = res
        
        self._verify_paths()
        self._setup_datasets()
    
    def _verify_paths(self):
        """ê²½ë¡œ ê²€ì¦"""
        for path, name in [
            (self.pre_path, "Pre"),
            (self.post_path, "Post"),
            (self.mask_path, "Mask")
        ]:
            if not path.exists():
                raise FileNotFoundError(f"{name} ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")
            
            tif_files = list(path.glob("*.tif"))
            if not tif_files:
                raise FileNotFoundError(f"{name} ë””ë ‰í† ë¦¬ì— TIF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    
    def _setup_datasets(self):
        """ë°ì´í„°ì…‹ ì´ˆê¸°í™”"""
        print(f"ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë”©: {self.data_dir}")
        
        # ê°œë³„ ë°ì´í„°ì…‹ ìƒì„±
        self.pre_dataset = ChangeDetectionPreDataset(
            paths=str(self.pre_path),
            crs=self.crs,
            res=self.res
        )
        
        self.post_dataset = ChangeDetectionPostDataset(
            paths=str(self.post_path),
            crs=self.crs,
            res=self.res
        )
        
        self.mask_dataset = ChangeDetectionMaskDataset(
            paths=str(self.mask_path),
            crs=self.crs,
            res=self.res
        )
        
        # êµì°¨ ë°ì´í„°ì…‹ (ëª¨ë“  ë°ì´í„°ê°€ ê°™ì€ ì˜ì—­ ì»¤ë²„í•˜ëŠ” ë¶€ë¶„ë§Œ)
        self.combined_dataset = self.pre_dataset & self.post_dataset & self.mask_dataset
        
        print(f"   âœ… Pre Dataset: {len(list(self.pre_path.glob('*.tif')))} files")
        print(f"   âœ… Post Dataset: {len(list(self.post_path.glob('*.tif')))} files")  
        print(f"   âœ… Mask Dataset: {len(list(self.mask_path.glob('*.tif')))} files")
        print(f"   ğŸ“Š Combined bounds: {self.combined_dataset.bounds}")
    
    def collate_fn(self, samples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
        """
        ì»¤ìŠ¤í…€ collate í•¨ìˆ˜
        Pre/Post/Maskë¥¼ ë¶„ë¦¬í•˜ì—¬ ë°°ì¹˜ êµ¬ì„±
        """
        pre_imgs = []
        post_imgs = []
        masks = []
        
        for sample in samples:
            img = sample['image']
            
            # TorchGeoëŠ” ì´ë¯¸ì§€ë¥¼ í•©ì³ì„œ ë°˜í™˜í•˜ë¯€ë¡œ ë¶„ë¦¬
            if img.shape[0] >= 6:
                pre_imgs.append(img[:3])
                post_imgs.append(img[3:6])
            else:
                # Fallback: ê°™ì€ ì´ë¯¸ì§€ ì‚¬ìš©
                pre_imgs.append(img[:3] if img.shape[0] >= 3 else img)
                post_imgs.append(img[:3] if img.shape[0] >= 3 else img)
            
            if 'mask' in sample:
                masks.append(sample['mask'])
        
        batch = {
            'pre': torch.stack(pre_imgs),
            'post': torch.stack(post_imgs),
        }
        
        if masks:
            batch['mask'] = torch.stack(masks)
        
        return batch
    
    def get_train_dataloader(self) -> DataLoader:
        """í•™ìŠµìš© DataLoader ë°˜í™˜"""
        sampler = RandomGeoSampler(
            dataset=self.combined_dataset,
            size=self.patch_size,
            length=self.samples_per_epoch
        )
        
        return DataLoader(
            self.combined_dataset,
            batch_size=self.batch_size,
            sampler=sampler,
            collate_fn=self.collate_fn,
            num_workers=self.num_workers,
            pin_memory=True
        )
    
    def get_val_dataloader(self, samples: int = 100) -> DataLoader:
        """ê²€ì¦ìš© DataLoader ë°˜í™˜"""
        sampler = RandomGeoSampler(
            dataset=self.combined_dataset,
            size=self.patch_size,
            length=samples
        )
        
        return DataLoader(
            self.combined_dataset,
            batch_size=self.batch_size,
            sampler=sampler,
            collate_fn=self.collate_fn,
            num_workers=self.num_workers,
            pin_memory=True
        )


# MinIO ìºì‹± ìœ í‹¸ë¦¬í‹°
class MinIODataCache:
    """
    MinIOì—ì„œ ë°ì´í„°ë¥¼ ë¡œì»¬ë¡œ ìºì‹±í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
    """
    
    def __init__(
        self,
        endpoint_url: str = "http://localhost:9000",
        access_key: Optional[str] = None,
        secret_key: Optional[str] = None,
        cache_dir: Optional[str] = None
    ):
        """
        Args:
            endpoint_url: MinIO ì—”ë“œí¬ì¸íŠ¸
            access_key: ì ‘ê·¼ í‚¤
            secret_key: ë¹„ë°€ í‚¤
            cache_dir: ë¡œì»¬ ìºì‹œ ë””ë ‰í† ë¦¬
        """
        import boto3
        from dotenv import load_dotenv
        
        load_dotenv()
        
        self.endpoint_url = endpoint_url
        self.access_key = access_key or os.getenv("AWS_ACCESS_KEY_ID", "minioadmin")
        self.secret_key = secret_key or os.getenv("AWS_SECRET_ACCESS_KEY", "minio_secure_password_2024")
        self.cache_dir = Path(cache_dir) if cache_dir else Path(tempfile.gettempdir()) / "minio_cache"
        
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.s3_client = boto3.client(
            "s3",
            endpoint_url=self.endpoint_url,
            aws_access_key_id=self.access_key,
            aws_secret_access_key=self.secret_key,
        )
    
    def download_dataset(
        self,
        bucket: str,
        prefix: str,
        target_dir: Optional[str] = None,
        skip_existing: bool = True
    ) -> Path:
        """
        MinIOì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
        
        Args:
            bucket: ë²„í‚·ëª…
            prefix: ê²½ë¡œ prefix
            target_dir: ëŒ€ìƒ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ìºì‹œ ë””ë ‰í† ë¦¬)
            skip_existing: ì´ë¯¸ ìˆëŠ” íŒŒì¼ ìŠ¤í‚µ
        
        Returns:
            ë‹¤ìš´ë¡œë“œëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        from tqdm import tqdm
        
        target = Path(target_dir) if target_dir else self.cache_dir / bucket / prefix
        target.mkdir(parents=True, exist_ok=True)
        
        # ê°ì²´ ëª©ë¡ ì¡°íšŒ
        paginator = self.s3_client.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=bucket, Prefix=prefix)
        
        objects = []
        for page in pages:
            if 'Contents' in page:
                objects.extend(page['Contents'])
        
        if not objects:
            print(f"âš ï¸ ë²„í‚·ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: s3://{bucket}/{prefix}")
            return target
        
        print(f"ğŸ“¥ MinIOì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘: s3://{bucket}/{prefix}")
        print(f"   ğŸ“Š ì´ {len(objects)}ê°œ íŒŒì¼")
        
        for obj in tqdm(objects, desc="ë‹¤ìš´ë¡œë“œ"):
            key = obj['Key']
            rel_path = key[len(prefix):].lstrip('/')
            
            if not rel_path:
                continue
            
            local_path = target / rel_path
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            if skip_existing and local_path.exists():
                continue
            
            self.s3_client.download_file(bucket, key, str(local_path))
        
        print(f"   âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {target}")
        return target


def build_data_module(config) -> ChangeDetectionDataModule:
    """
    Configì—ì„œ DataModule ë¹Œë“œ
    """
    if hasattr(config, 'data'):
        data_cfg = config.data.local
        data_dir = data_cfg.root_dir
        pre_dir = data_cfg.pre_dir
        post_dir = data_cfg.post_dir
        mask_dir = data_cfg.mask_dir
    else:
        data_cfg = config.get("data", {}).get("local", {})
        data_dir = data_cfg.get("root_dir", "./data/change_detection")
        pre_dir = data_cfg.get("pre_dir", "pre")
        post_dir = data_cfg.get("post_dir", "post")
        mask_dir = data_cfg.get("mask_dir", "mask")
    
    if hasattr(config, 'torchgeo'):
        tg_cfg = config.torchgeo
        patch_size = tg_cfg.patch_size
        samples_per_epoch = tg_cfg.samples_per_epoch
    else:
        tg_cfg = config.get("torchgeo", {})
        patch_size = tg_cfg.get("patch_size", 256)
        samples_per_epoch = tg_cfg.get("samples_per_epoch", 1000)
    
    if hasattr(config, 'training'):
        batch_size = config.training.batch_size
    else:
        batch_size = config.get("training", {}).get("batch_size", 8)
    
    if hasattr(config, 'hardware'):
        num_workers = config.hardware.num_workers
    else:
        num_workers = config.get("hardware", {}).get("num_workers", 4)
    
    return ChangeDetectionDataModule(
        data_dir=data_dir,
        pre_dir=pre_dir,
        post_dir=post_dir,
        mask_dir=mask_dir,
        patch_size=patch_size,
        batch_size=batch_size,
        samples_per_epoch=samples_per_epoch,
        num_workers=num_workers
    )


# ê°€ì§œ ë°ì´í„° ìƒì„± ìœ í‹¸ë¦¬í‹° (í…ŒìŠ¤íŠ¸ìš©)
def create_dummy_data(data_dir: str, size: int = 1024) -> Path:
    """í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„±"""
    data_path = Path(data_dir)
    pre_dir = data_path / "pre"
    post_dir = data_path / "post"
    mask_dir = data_path / "mask"
    
    for d in [pre_dir, post_dir, mask_dir]:
        d.mkdir(parents=True, exist_ok=True)
    
    # ì¢Œí‘œê³„ ì„¤ì •
    west, south, east, north = 126.9, 37.5, 127.0, 37.6
    transform = from_bounds(west, south, east, north, size, size)
    crs = CRS.from_epsg(4326)
    
    profile = {
        'driver': 'GTiff',
        'dtype': 'uint8',
        'width': size,
        'height': size,
        'count': 3,
        'crs': crs,
        'transform': transform,
        'compress': 'lzw'
    }
    
    # Pre ì´ë¯¸ì§€
    np.random.seed(42)
    pre_data = np.random.randint(0, 255, (3, size, size), dtype=np.uint8)
    with rasterio.open(pre_dir / "pre_image.tif", 'w', **profile) as dst:
        dst.write(pre_data)
    
    # Post ì´ë¯¸ì§€
    np.random.seed(123)
    post_data = np.random.randint(0, 255, (3, size, size), dtype=np.uint8)
    with rasterio.open(post_dir / "post_image.tif", 'w', **profile) as dst:
        dst.write(post_data)
    
    # Mask
    profile['count'] = 1
    mask_data = np.zeros((1, size, size), dtype=np.uint8)
    for _ in range(10):
        x, y = np.random.randint(0, size-100), np.random.randint(0, size-100)
        w, h = np.random.randint(20, 100), np.random.randint(20, 100)
        mask_data[0, y:y+h, x:x+w] = 1
    
    with rasterio.open(mask_dir / "mask.tif", 'w', **profile) as dst:
        dst.write(mask_data)
    
    print(f"âœ… ë”ë¯¸ ë°ì´í„° ìƒì„±: {data_path}")
    return data_path


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("=== DataModule í…ŒìŠ¤íŠ¸ ===")
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„±
    data_dir = "./data/cd_test"
    create_dummy_data(data_dir)
    
    # DataModule ìƒì„±
    dm = ChangeDetectionDataModule(
        data_dir=data_dir,
        patch_size=256,
        batch_size=4,
        samples_per_epoch=10,
        num_workers=0
    )
    
    # DataLoader í…ŒìŠ¤íŠ¸
    train_loader = dm.get_train_dataloader()
    
    for batch in train_loader:
        print(f"Pre shape: {batch['pre'].shape}")
        print(f"Post shape: {batch['post'].shape}")
        print(f"Mask shape: {batch['mask'].shape}")
        break
