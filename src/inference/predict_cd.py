#!/usr/bin/env python3
"""
ë³€í™”íƒì§€ ì¶”ë¡ (Inference) ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ìƒˆë¡œìš´ ì´ë¯¸ì§€ì— ëŒ€í•´ ë³€í™”íƒì§€ ìˆ˜í–‰

ì‚¬ìš©ë²•:
    # Run IDë¡œ ëª¨ë¸ ë¡œë“œ
    python src/inference/predict_cd.py --run-id abc123 --pre pre.tif --post post.tif -o output/

    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì§ì ‘ ì§€ì •
    python src/inference/predict_cd.py --checkpoint checkpoints/best_model.pth --pre pre.tif --post post.tif
"""

import argparse
import os
import sys
import tempfile
from pathlib import Path
from typing import Optional, Tuple, Union

import numpy as np
import rasterio
import torch
from rasterio.windows import Window

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# .env ë¡œë“œ
from dotenv import load_dotenv
env_file = PROJECT_ROOT / ".env"
if env_file.exists():
    load_dotenv(env_file)

from src.models.unet import ChangeDetectionModel
from src.utils.visualization import (
    visualize_change_detection,
    save_prediction_geotiff,
    create_change_overlay
)


class ChangeDetectionPredictor:
    """
    ë³€í™”íƒì§€ ì¶”ë¡  í´ë˜ìŠ¤
    """
    
    def __init__(
        self,
        checkpoint_path: Optional[str] = None,
        run_id: Optional[str] = None,
        device: str = "auto"
    ):
        """
        Args:
            checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            run_id: MLflow Run ID
            device: ë””ë°”ì´ìŠ¤ (auto, cuda, cpu)
        """
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)
        
        print(f"ğŸ“± Device: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = None
        self.config = None
        
        if checkpoint_path:
            self._load_from_checkpoint(checkpoint_path)
        elif run_id:
            self._load_from_mlflow(run_id)
        else:
            raise ValueError("checkpoint_path ë˜ëŠ” run_id ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
    
    def _load_from_checkpoint(self, checkpoint_path: str):
        """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì—ì„œ ëª¨ë¸ ë¡œë“œ"""
        checkpoint_path = Path(checkpoint_path)
        
        if not checkpoint_path.exists():
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        
        print(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}")
        
        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
        self.config = checkpoint.get('config', {})
        
        # ëª¨ë¸ ìƒì„±
        model_cfg = self.config.get('model', {})
        self.model = ChangeDetectionModel(
            architecture=model_cfg.get('architecture', 'unet'),
            encoder_name=model_cfg.get('encoder', {}).get('name', 'resnet50'),
            encoder_weights=None,  # ê°€ì¤‘ì¹˜ëŠ” ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë¡œë“œ
            in_channels=model_cfg.get('in_channels', 6),
            num_classes=model_cfg.get('num_classes', 2)
        )
        
        # ê°€ì¤‘ì¹˜ ë¡œë“œ
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model = self.model.to(self.device)
        self.model.eval()
        
        print(f"   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        if 'val_iou' in checkpoint:
            print(f"   ğŸ“Š Checkpoint IoU: {checkpoint['val_iou']:.4f}")
    
    def _load_from_mlflow(self, run_id: str):
        """MLflow Runì—ì„œ ëª¨ë¸ ë¡œë“œ"""
        import mlflow
        
        tracking_uri = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
        mlflow.set_tracking_uri(tracking_uri)
        
        print(f"ğŸ“¡ MLflow: {tracking_uri}")
        print(f"ğŸ” Run ID: {run_id}")
        
        client = mlflow.tracking.MlflowClient()
        
        # Run ì •ë³´ ì¡°íšŒ
        run = client.get_run(run_id)
        print(f"   ğŸ“Œ Run Name: {run.info.run_name}")
        
        # ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ
        artifact_path = client.download_artifacts(run_id, "checkpoints")
        print(f"   ğŸ“¥ ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ: {artifact_path}")
        
        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì°¾ê¸°
        artifact_dir = Path(artifact_path)
        checkpoint_files = list(artifact_dir.glob("*.pth"))
        
        if not checkpoint_files:
            raise FileNotFoundError(f"Run {run_id}ì—ì„œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # best_model ë˜ëŠ” final_model ìš°ì„ 
        checkpoint_path = None
        for pattern in ["best_model*.pth", "final_model.pth"]:
            matches = list(artifact_dir.glob(pattern))
            if matches:
                checkpoint_path = matches[0]
                break
        
        if checkpoint_path is None:
            checkpoint_path = checkpoint_files[0]
        
        self._load_from_checkpoint(str(checkpoint_path))
    
    def load_geotiff(self, path: str) -> Tuple[np.ndarray, dict]:
        """
        GeoTIFF ì´ë¯¸ì§€ ë¡œë“œ
        
        Returns:
            (ì´ë¯¸ì§€ ë°°ì—´ [C, H, W], ë©”íƒ€ë°ì´í„°)
        """
        with rasterio.open(path) as src:
            image = src.read()
            meta = {
                'crs': src.crs,
                'transform': src.transform,
                'width': src.width,
                'height': src.height,
                'bounds': src.bounds
            }
        return image, meta
    
    def predict_single(
        self,
        pre_image: np.ndarray,
        post_image: np.ndarray,
        patch_size: int = 256,
        overlap: int = 32
    ) -> np.ndarray:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ìŒì— ëŒ€í•œ ì˜ˆì¸¡
        
        Args:
            pre_image: Pre ì´ë¯¸ì§€ [C, H, W]
            post_image: Post ì´ë¯¸ì§€ [C, H, W]
            patch_size: íŒ¨ì¹˜ í¬ê¸°
            overlap: ì˜¤ë²„ë© í¬ê¸°
        
        Returns:
            ì˜ˆì¸¡ ë§ˆìŠ¤í¬ [H, W]
        """
        _, h, w = pre_image.shape
        
        # ì‘ì€ ì´ë¯¸ì§€ëŠ” í•œ ë²ˆì— ì²˜ë¦¬
        if h <= patch_size and w <= patch_size:
            return self._predict_patch(pre_image, post_image)
        
        # í° ì´ë¯¸ì§€ëŠ” ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì²˜ë¦¬
        return self._predict_sliding_window(
            pre_image, post_image, patch_size, overlap
        )
    
    def _predict_patch(
        self,
        pre_image: np.ndarray,
        post_image: np.ndarray
    ) -> np.ndarray:
        """íŒ¨ì¹˜ ë‹¨ìœ„ ì˜ˆì¸¡"""
        # í…ì„œë¡œ ë³€í™˜
        pre_tensor = torch.from_numpy(pre_image).float().unsqueeze(0).to(self.device)
        post_tensor = torch.from_numpy(post_image).float().unsqueeze(0).to(self.device)
        
        # ì •ê·œí™” (0-255 -> 0-1)
        if pre_tensor.max() > 1.0:
            pre_tensor = pre_tensor / 255.0
        if post_tensor.max() > 1.0:
            post_tensor = post_tensor / 255.0
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = self.model(pre_tensor, post_tensor)
            pred = outputs.argmax(dim=1).squeeze().cpu().numpy()
        
        return pred
    
    def _predict_sliding_window(
        self,
        pre_image: np.ndarray,
        post_image: np.ndarray,
        patch_size: int,
        overlap: int
    ) -> np.ndarray:
        """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡ (ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ìš©)"""
        _, h, w = pre_image.shape
        stride = patch_size - overlap
        
        # ê²°ê³¼ ë° ì¹´ìš´íŠ¸ ë°°ì—´
        prediction = np.zeros((h, w), dtype=np.float32)
        count = np.zeros((h, w), dtype=np.float32)
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
        y_positions = list(range(0, h - patch_size + 1, stride))
        x_positions = list(range(0, w - patch_size + 1, stride))
        
        # ë§ˆì§€ë§‰ íŒ¨ì¹˜ê°€ ëˆ„ë½ë˜ì§€ ì•Šë„ë¡
        if y_positions[-1] + patch_size < h:
            y_positions.append(h - patch_size)
        if x_positions[-1] + patch_size < w:
            x_positions.append(w - patch_size)
        
        from tqdm import tqdm
        total = len(y_positions) * len(x_positions)
        
        with tqdm(total=total, desc="Predicting") as pbar:
            for y in y_positions:
                for x in x_positions:
                    # íŒ¨ì¹˜ ì¶”ì¶œ
                    pre_patch = pre_image[:, y:y+patch_size, x:x+patch_size]
                    post_patch = post_image[:, y:y+patch_size, x:x+patch_size]
                    
                    # ì˜ˆì¸¡
                    pred_patch = self._predict_patch(pre_patch, post_patch)
                    
                    # ëˆ„ì 
                    prediction[y:y+patch_size, x:x+patch_size] += pred_patch
                    count[y:y+patch_size, x:x+patch_size] += 1
                    
                    pbar.update(1)
        
        # í‰ê· 
        prediction = prediction / np.maximum(count, 1)
        
        # ì„ê³„ê°’ ì ìš©
        prediction = (prediction > 0.5).astype(np.uint8)
        
        return prediction
    
    def predict_files(
        self,
        pre_path: str,
        post_path: str,
        output_dir: str,
        save_geotiff: bool = True,
        save_visualization: bool = True,
        patch_size: int = 256
    ) -> dict:
        """
        íŒŒì¼ ê¸°ë°˜ ì˜ˆì¸¡
        
        Args:
            pre_path: Pre ì´ë¯¸ì§€ ê²½ë¡œ
            post_path: Post ì´ë¯¸ì§€ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            save_geotiff: GeoTIFF ì €ì¥ ì—¬ë¶€
            save_visualization: ì‹œê°í™” ì €ì¥ ì—¬ë¶€
            patch_size: íŒ¨ì¹˜ í¬ê¸°
        
        Returns:
            ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print("\nğŸ“‚ ì…ë ¥ íŒŒì¼ ë¡œë“œ...")
        print(f"   Pre: {pre_path}")
        print(f"   Post: {post_path}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        pre_image, pre_meta = self.load_geotiff(pre_path)
        post_image, post_meta = self.load_geotiff(post_path)
        
        print(f"   ì´ë¯¸ì§€ í¬ê¸°: {pre_image.shape}")
        
        # ì˜ˆì¸¡
        print("\nğŸ”® ë³€í™”íƒì§€ ìˆ˜í–‰ ì¤‘...")
        prediction = self.predict_single(pre_image, post_image, patch_size)
        
        results = {
            "prediction": prediction,
            "pre_meta": pre_meta,
            "post_meta": post_meta
        }
        
        # GeoTIFF ì €ì¥
        if save_geotiff:
            geotiff_path = output_dir / "prediction.tif"
            save_prediction_geotiff(
                prediction,
                str(geotiff_path),
                reference_path=pre_path
            )
            results["geotiff_path"] = str(geotiff_path)
        
        # ì‹œê°í™” ì €ì¥
        if save_visualization:
            viz_path = output_dir / "visualization.png"
            visualize_change_detection(
                pre_image,
                post_image,
                prediction,
                save_path=str(viz_path)
            )
            results["visualization_path"] = str(viz_path)
        
        # í†µê³„
        change_ratio = prediction.sum() / prediction.size * 100
        print(f"\nğŸ“Š ë³€í™” ì˜ì—­: {change_ratio:.2f}%")
        results["change_ratio"] = change_ratio
        
        return results


def main():
    parser = argparse.ArgumentParser(
        description="ë³€í™”íƒì§€ ì¶”ë¡ ",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # ëª¨ë¸ ì†ŒìŠ¤
    model_group = parser.add_mutually_exclusive_group(required=True)
    model_group.add_argument(
        "--run-id", "-r",
        type=str,
        help="MLflow Run ID"
    )
    model_group.add_argument(
        "--checkpoint", "-c",
        type=str,
        help="ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ"
    )
    
    # ì…ë ¥
    parser.add_argument(
        "--pre", "-p",
        type=str,
        required=True,
        help="Pre ì´ë¯¸ì§€ ê²½ë¡œ (GeoTIFF)"
    )
    parser.add_argument(
        "--post", "-t",
        type=str,
        required=True,
        help="Post ì´ë¯¸ì§€ ê²½ë¡œ (GeoTIFF)"
    )
    
    # ì¶œë ¥
    parser.add_argument(
        "--output", "-o",
        type=str,
        default="./output",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    
    # ì˜µì…˜
    parser.add_argument(
        "--patch-size",
        type=int,
        default=256,
        help="íŒ¨ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 256)"
    )
    parser.add_argument(
        "--no-geotiff",
        action="store_true",
        help="GeoTIFF ì €ì¥ ì•ˆ í•¨"
    )
    parser.add_argument(
        "--no-viz",
        action="store_true",
        help="ì‹œê°í™” ì €ì¥ ì•ˆ í•¨"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="ë””ë°”ì´ìŠ¤ (auto, cuda, cpu)"
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ”® ë³€í™”íƒì§€ ì¶”ë¡  (Inference)")
    print("=" * 60)
    
    # Predictor ìƒì„±
    predictor = ChangeDetectionPredictor(
        checkpoint_path=args.checkpoint,
        run_id=args.run_id,
        device=args.device
    )
    
    # ì˜ˆì¸¡
    results = predictor.predict_files(
        pre_path=args.pre,
        post_path=args.post,
        output_dir=args.output,
        save_geotiff=not args.no_geotiff,
        save_visualization=not args.no_viz,
        patch_size=args.patch_size
    )
    
    print("\n" + "=" * 60)
    print("âœ… ì¶”ë¡  ì™„ë£Œ!")
    print("=" * 60)
    print(f"   ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output}")
    
    if "geotiff_path" in results:
        print(f"   ğŸ“„ GeoTIFF: {results['geotiff_path']}")
    if "visualization_path" in results:
        print(f"   ğŸ–¼ï¸  ì‹œê°í™”: {results['visualization_path']}")


if __name__ == "__main__":
    main()
