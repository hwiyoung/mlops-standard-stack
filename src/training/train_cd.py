#!/usr/bin/env python3
"""
ë³€í™”íƒì§€(Change Detection) í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
YAML ì„¤ì • íŒŒì¼ ê¸°ë°˜ í•™ìŠµ + MLflow ë¡œê¹… + ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬

ì‚¬ìš©ë²•:
    python src/training/train_cd.py --config configs/train_cd.yaml
    python src/training/train_cd.py -c configs/train_cd.yaml -o training.epochs=100
"""

import os
import sys
import tempfile
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€ (ì„í¬íŠ¸ ì „ì—)
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (AWS_ACCESS_KEY_ID ë“±)
from dotenv import load_dotenv
env_file = PROJECT_ROOT / ".env"
if env_file.exists():
    load_dotenv(env_file)
    print(f"âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ: {env_file}")

import mlflow
import mlflow.pytorch
import numpy as np
import torch
import torch.nn as nn
from torch.cuda.amp import GradScaler, autocast
from tqdm import tqdm

from src.utils.config import parse_args_with_config, load_config
from src.models.unet import build_model, build_loss
from src.data_loaders.cd_dataset import build_data_module, create_dummy_data


# ============================================
# ë©”íŠ¸ë¦­ ê³„ì‚°
# ============================================
def calculate_metrics(pred: torch.Tensor, target: torch.Tensor, num_classes: int = 2) -> dict:
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ ë©”íŠ¸ë¦­ ê³„ì‚°
    
    Args:
        pred: ì˜ˆì¸¡ logits [B, C, H, W]
        target: íƒ€ê²Ÿ ë§ˆìŠ¤í¬ [B, H, W] ë˜ëŠ” [B, 1, H, W]
        num_classes: í´ë˜ìŠ¤ ìˆ˜
    
    Returns:
        ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    pred_mask = pred.argmax(dim=1).flatten()
    target_mask = target.flatten() if target.dim() == 3 else target[:, 0].flatten()
    
    # IoU ê³„ì‚°
    ious = []
    for cls in range(num_classes):
        pred_cls = (pred_mask == cls)
        target_cls = (target_mask == cls)
        intersection = (pred_cls & target_cls).sum().float()
        union = (pred_cls | target_cls).sum().float()
        if union > 0:
            ious.append((intersection / union).item())
    
    mean_iou = np.mean(ious) if ious else 0.0
    
    # Accuracy
    correct = (pred_mask == target_mask).sum().float()
    total = target_mask.numel()
    accuracy = (correct / total).item()
    
    # F1 Score (binary)
    tp = ((pred_mask == 1) & (target_mask == 1)).sum().float()
    fp = ((pred_mask == 1) & (target_mask == 0)).sum().float()
    fn = ((pred_mask == 0) & (target_mask == 1)).sum().float()
    
    precision = (tp / (tp + fp + 1e-8)).item()
    recall = (tp / (tp + fn + 1e-8)).item()
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    
    return {
        "iou": mean_iou,
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f1": f1
    }


# ============================================
# ì‹œê°í™”
# ============================================
def visualize_predictions(
    pre: torch.Tensor,
    post: torch.Tensor,
    pred: torch.Tensor,
    target: torch.Tensor,
    save_path: str,
    num_samples: int = 4
):
    """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
    import matplotlib.pyplot as plt
    
    num_samples = min(num_samples, pre.shape[0])
    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))
    
    if num_samples == 1:
        axes = axes.reshape(1, -1)
    
    for i in range(num_samples):
        # Pre
        pre_img = pre[i].permute(1, 2, 0).cpu().numpy()
        pre_img = (pre_img - pre_img.min()) / (pre_img.max() - pre_img.min() + 1e-8)
        axes[i, 0].imshow(pre_img[:, :, :3])
        axes[i, 0].set_title("Pre Image")
        axes[i, 0].axis('off')
        
        # Post
        post_img = post[i].permute(1, 2, 0).cpu().numpy()
        post_img = (post_img - post_img.min()) / (post_img.max() - post_img.min() + 1e-8)
        axes[i, 1].imshow(post_img[:, :, :3])
        axes[i, 1].set_title("Post Image")
        axes[i, 1].axis('off')
        
        # Target
        target_mask = target[i].squeeze().cpu().numpy()
        axes[i, 2].imshow(target_mask, cmap='RdYlGn_r')
        axes[i, 2].set_title("Ground Truth")
        axes[i, 2].axis('off')
        
        # Prediction
        pred_mask = pred[i].argmax(dim=0).cpu().numpy()
        axes[i, 3].imshow(pred_mask, cmap='RdYlGn_r')
        axes[i, 3].set_title("Prediction")
        axes[i, 3].axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    return save_path


# ============================================
# í•™ìŠµ í•¨ìˆ˜
# ============================================
def train_one_epoch(
    model: nn.Module,
    dataloader,
    criterion: nn.Module,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
    scaler: GradScaler = None,
    use_amp: bool = False
) -> dict:
    """í•œ ì—í­ í•™ìŠµ"""
    model.train()
    
    total_loss = 0.0
    all_metrics = {"iou": [], "accuracy": [], "f1": []}
    
    pbar = tqdm(dataloader, desc="Training", leave=False)
    for batch in pbar:
        pre = batch['pre'].float().to(device)
        post = batch['post'].float().to(device)
        mask = batch['mask'].long().to(device)
        
        # ë§ˆìŠ¤í¬ ì°¨ì› ì²˜ë¦¬
        if mask.dim() == 4:
            mask = mask[:, 0]
        
        optimizer.zero_grad()
        
        if use_amp and scaler is not None:
            with autocast():
                outputs = model(pre, post)
                loss = criterion(outputs, mask)
            
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(pre, post)
            loss = criterion(outputs, mask)
            loss.backward()
            optimizer.step()
        
        total_loss += loss.item()
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        with torch.no_grad():
            metrics = calculate_metrics(outputs, mask)
            for key in all_metrics:
                all_metrics[key].append(metrics[key])
        
        pbar.set_postfix(loss=f"{loss.item():.4f}", iou=f"{metrics['iou']:.4f}")
    
    avg_loss = total_loss / len(dataloader)
    avg_metrics = {k: np.mean(v) for k, v in all_metrics.items()}
    avg_metrics["loss"] = avg_loss
    
    return avg_metrics


def validate(
    model: nn.Module,
    dataloader,
    criterion: nn.Module,
    device: torch.device
) -> dict:
    """ê²€ì¦"""
    model.eval()
    
    total_loss = 0.0
    all_metrics = {"iou": [], "accuracy": [], "f1": []}
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Validation", leave=False):
            pre = batch['pre'].float().to(device)
            post = batch['post'].float().to(device)
            mask = batch['mask'].long().to(device)
            
            if mask.dim() == 4:
                mask = mask[:, 0]
            
            outputs = model(pre, post)
            loss = criterion(outputs, mask)
            
            total_loss += loss.item()
            
            metrics = calculate_metrics(outputs, mask)
            for key in all_metrics:
                all_metrics[key].append(metrics[key])
    
    avg_loss = total_loss / len(dataloader)
    avg_metrics = {k: np.mean(v) for k, v in all_metrics.items()}
    avg_metrics["loss"] = avg_loss
    
    return avg_metrics


# ============================================
# ë©”ì¸ í•™ìŠµ í•¨ìˆ˜
# ============================================
def train(config):
    """
    ë©”ì¸ í•™ìŠµ í•¨ìˆ˜
    
    Args:
        config: Config ê°ì²´
    """
    print("=" * 60)
    print("ğŸš€ ë³€í™”íƒì§€(Change Detection) í•™ìŠµ ì‹œì‘")
    print("=" * 60)
    
    # ì¬í˜„ì„± ì„¤ì •
    seed = config.reproducibility.seed
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if config.hardware.device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(config.hardware.device)
    print(f"ğŸ“± Device: {device}")
    
    # ë°ì´í„° ì¤€ë¹„
    print("\nğŸ“‚ ë°ì´í„° ë¡œë”©...")
    data_dir = Path(config.data.local.root_dir)
    
    if not data_dir.exists():
        print("   âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...")
        create_dummy_data(str(data_dir))
    
    data_module = build_data_module(config)
    train_loader = data_module.get_train_dataloader()
    val_loader = data_module.get_val_dataloader()
    
    # ëª¨ë¸ ìƒì„±
    print("\nğŸ§  ëª¨ë¸ ìƒì„±...")
    model = build_model(config).to(device)
    
    # ì†ì‹¤ í•¨ìˆ˜
    criterion = build_loss(config)
    
    # ì˜µí‹°ë§ˆì´ì €
    opt_cfg = config.training.optimizer
    if opt_cfg.name.lower() == "adamw":
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=opt_cfg.lr,
            weight_decay=opt_cfg.weight_decay,
            betas=tuple(opt_cfg.betas)
        )
    elif opt_cfg.name.lower() == "adam":
        optimizer = torch.optim.Adam(
            model.parameters(),
            lr=opt_cfg.lr,
            betas=tuple(opt_cfg.betas)
        )
    else:
        optimizer = torch.optim.SGD(
            model.parameters(),
            lr=opt_cfg.lr,
            weight_decay=opt_cfg.weight_decay,
            momentum=0.9
        )
    
    # ìŠ¤ì¼€ì¤„ëŸ¬
    sched_cfg = config.training.scheduler
    if sched_cfg.name == "cosine":
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=config.training.epochs - sched_cfg.warmup_epochs,
            eta_min=sched_cfg.min_lr
        )
    else:
        scheduler = None
    
    # AMP
    use_amp = config.hardware.mixed_precision and device.type == "cuda"
    scaler = GradScaler() if use_amp else None
    if use_amp:
        print("   âš¡ Mixed Precision í™œì„±í™”")
    
    # MLflow ì„¤ì •
    mlflow.set_tracking_uri(config.logging.mlflow.tracking_uri)
    mlflow.set_experiment(config.experiment.name)
    
    # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
    ckpt_dir = Path(config.checkpoint.save_dir)
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    
    # í•™ìŠµ ì‹œì‘
    run_name = config.experiment.run_name or f"cd-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
    
    with mlflow.start_run(run_name=run_name):
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params({
            "model_architecture": config.model.architecture,
            "encoder": config.model.encoder.name,
            "epochs": config.training.epochs,
            "batch_size": config.training.batch_size,
            "learning_rate": config.training.optimizer.lr,
            "optimizer": config.training.optimizer.name,
            "loss": config.training.loss.name,
            "patch_size": config.torchgeo.patch_size,
            "device": str(device)
        })
        
        # íƒœê·¸ ë¡œê¹…
        if hasattr(config.experiment, 'tags'):
            tags = config.experiment.tags
            mlflow.set_tags({
                "project": tags.project,
                "task": tags.task,
                "environment": tags.environment
            })
        
        best_iou = 0.0
        best_model_path = None
        epochs = config.training.epochs
        
        print(f"\nğŸƒ í•™ìŠµ ì‹œì‘ ({epochs} epochs)")
        
        for epoch in range(1, epochs + 1):
            print(f"\nğŸ“Œ Epoch {epoch}/{epochs}")
            
            # í•™ìŠµ
            train_metrics = train_one_epoch(
                model, train_loader, criterion, optimizer, device, scaler, use_amp
            )
            
            # ê²€ì¦
            val_metrics = validate(model, val_loader, criterion, device)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤í…
            if scheduler is not None:
                scheduler.step()
            
            # ë©”íŠ¸ë¦­ ë¡œê¹…
            mlflow.log_metrics({
                "train_loss": train_metrics["loss"],
                "train_iou": train_metrics["iou"],
                "train_f1": train_metrics["f1"],
                "val_loss": val_metrics["loss"],
                "val_iou": val_metrics["iou"],
                "val_f1": val_metrics["f1"],
                "learning_rate": optimizer.param_groups[0]['lr']
            }, step=epoch)
            
            print(f"   Train - Loss: {train_metrics['loss']:.4f}, IoU: {train_metrics['iou']:.4f}")
            print(f"   Val   - Loss: {val_metrics['loss']:.4f}, IoU: {val_metrics['iou']:.4f}")
            
            # ì‹œê°í™” (ì²« ì—í­, ì¤‘ê°„, ë§ˆì§€ë§‰)
            if epoch == 1 or epoch == epochs // 2 or epoch == epochs:
                with tempfile.TemporaryDirectory() as tmpdir:
                    for batch in val_loader:
                        pre = batch['pre'].float().to(device)
                        post = batch['post'].float().to(device)
                        mask = batch['mask']
                        
                        with torch.no_grad():
                            pred = model(pre, post)
                        
                        viz_path = os.path.join(tmpdir, f"predictions_epoch_{epoch:03d}.png")
                        visualize_predictions(pre, post, pred, mask, viz_path)
                        mlflow.log_artifact(viz_path, artifact_path="visualizations")
                        break
            
            # Best ëª¨ë¸ ì €ì¥
            if val_metrics["iou"] > best_iou:
                best_iou = val_metrics["iou"]
                best_model_path = ckpt_dir / f"best_model_epoch_{epoch:03d}_iou_{best_iou:.4f}.pth"
                
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_iou': best_iou,
                    'config': config.to_dict()
                }, best_model_path)
                
                print(f"   âœ… Best ëª¨ë¸ ì €ì¥: {best_model_path.name}")
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥ ë° ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ
        print("\nğŸ“¦ ëª¨ë¸ ì €ì¥ ì¤‘...")
        
        # ìµœì¢… ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        final_model_path = ckpt_dir / "final_model.pth"
        torch.save({
            'model_state_dict': model.state_dict(),
            'config': config.to_dict(),
            'best_val_iou': best_iou
        }, final_model_path)
        print(f"   âœ… ìµœì¢… ëª¨ë¸ ì €ì¥: {final_model_path}")
        
        # ìµœì¢… ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metrics({
            "best_val_iou": best_iou
        })
        
        # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥
        if best_model_path and best_model_path.exists():
            mlflow.log_artifact(str(best_model_path), artifact_path="checkpoints")
        mlflow.log_artifact(str(final_model_path), artifact_path="checkpoints")
        print("   âœ… ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ ì™„ë£Œ (MinIO)")
        
        print("\n" + "=" * 60)
        print("âœ… í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)
        print(f"   ğŸ“Š Best Val IoU: {best_iou:.4f}")
        print(f"   ğŸ“¦ Checkpoints: {ckpt_dir}")
        print(f"   ğŸŒ MLflow UI: {config.logging.mlflow.tracking_uri}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args, config = parse_args_with_config()
    train(config)


if __name__ == "__main__":
    main()
