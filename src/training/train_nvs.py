#!/usr/bin/env python3
"""
Novel View Synthesis (3D Gaussian Splatting) í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
gsplat ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ + MLflow ë¡œê¹… + MinIO ë°ì´í„°/ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬

ì‚¬ìš©ë²•:
    python src/training/train_nvs.py --config configs/train_nvs.yaml
    python src/training/train_nvs.py -c configs/train_nvs.yaml -o training.iterations=7000
    
Docker:
    docker-compose run nvs-train --config configs/train_nvs.yaml
"""

import json
import os
import shutil
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import cv2
import mlflow
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# .env ë¡œë“œ
from dotenv import load_dotenv
env_file = PROJECT_ROOT / ".env"
if env_file.exists():
    load_dotenv(env_file)
    print(f"âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ: {env_file}")

from src.utils.config import parse_args_with_config, load_config
from src.models.gaussian_model import GaussianModel, GaussianModelConfig, build_gaussian_model

# gsplat ê°€ìš©ì„± ì²´í¬
try:
    import gsplat
    from gsplat import rasterization
    GSPLAT_AVAILABLE = True
except ImportError:
    GSPLAT_AVAILABLE = False
    print("âš ï¸ gsplat ë¯¸ì„¤ì¹˜. Mock ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")


# ============================================
# VRAM ëª¨ë‹ˆí„°ë§
# ============================================
def get_gpu_memory_usage() -> dict:
    """GPU VRAM ì‚¬ìš©ëŸ‰ ì¡°íšŒ"""
    if not torch.cuda.is_available():
        return {"allocated_mb": 0, "reserved_mb": 0, "max_allocated_mb": 0, "utilization_percent": 0}
    
    allocated = torch.cuda.memory_allocated() / (1024 ** 2)
    reserved = torch.cuda.memory_reserved() / (1024 ** 2)
    max_allocated = torch.cuda.max_memory_allocated() / (1024 ** 2)
    total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 2)
    utilization = (allocated / total) * 100 if total > 0 else 0
    
    return {
        "allocated_mb": allocated,
        "reserved_mb": reserved,
        "max_allocated_mb": max_allocated,
        "utilization_percent": utilization,
        "total_mb": total
    }


def log_gpu_metrics(step: int):
    """GPU ë©”íŠ¸ë¦­ì„ MLflowì— ë¡œê¹…"""
    mem = get_gpu_memory_usage()
    mlflow.log_metrics({
        "gpu/vram_allocated_mb": mem["allocated_mb"],
        "gpu/vram_reserved_mb": mem["reserved_mb"],
        "gpu/vram_utilization_percent": mem["utilization_percent"]
    }, step=step)


# ============================================
# ì¹´ë©”ë¼ & ì´ë¯¸ì§€ ë¡œë”©
# ============================================
class Camera:
    """ë‹¨ì¼ ì¹´ë©”ë¼ ë·°"""
    def __init__(
        self,
        R: np.ndarray,          # [3, 3] íšŒì „ í–‰ë ¬
        T: np.ndarray,          # [3] ë³€í™˜ ë²¡í„°
        FoVx: float,            # ìˆ˜í‰ FOV (radians)
        FoVy: float,            # ìˆ˜ì§ FOV (radians)
        image: np.ndarray,      # [H, W, 3] ì´ë¯¸ì§€
        image_name: str,
        width: int,
        height: int,
        device: str = "cuda"
    ):
        self.R = R
        self.T = T
        self.FoVx = FoVx
        self.FoVy = FoVy
        self.image_name = image_name
        self.width = width
        self.height = height
        self.device = device
        
        # ì´ë¯¸ì§€ í…ì„œ
        self.original_image = torch.from_numpy(image).permute(2, 0, 1).float().to(device) / 255.0
        
        # World-to-Camera ë³€í™˜
        self.view_matrix = self._get_view_matrix()
        self.projection_matrix = self._get_projection_matrix()
        self.full_proj_transform = self.projection_matrix @ self.view_matrix
        self.camera_center = self._get_camera_center()
    
    def _get_view_matrix(self) -> torch.Tensor:
        """World-to-Camera ë³€í™˜ í–‰ë ¬"""
        Rt = np.zeros((4, 4))
        Rt[:3, :3] = self.R.T
        Rt[:3, 3] = self.T
        Rt[3, 3] = 1.0
        return torch.tensor(Rt, dtype=torch.float32, device=self.device)
    
    def _get_projection_matrix(self, znear: float = 0.01, zfar: float = 100.0) -> torch.Tensor:
        """Projection í–‰ë ¬"""
        tan_half_fov_y = np.tan(self.FoVy / 2)
        tan_half_fov_x = np.tan(self.FoVx / 2)
        
        top = tan_half_fov_y * znear
        bottom = -top
        right = tan_half_fov_x * znear
        left = -right
        
        P = torch.zeros(4, 4, device=self.device)
        P[0, 0] = 2.0 * znear / (right - left)
        P[1, 1] = 2.0 * znear / (top - bottom)
        P[0, 2] = (right + left) / (right - left)
        P[1, 2] = (top + bottom) / (top - bottom)
        P[2, 2] = -(zfar + znear) / (zfar - znear)
        P[2, 3] = -2.0 * zfar * znear / (zfar - znear)
        P[3, 2] = -1.0
        
        return P
    
    def _get_camera_center(self) -> torch.Tensor:
        """ì¹´ë©”ë¼ ì›”ë“œ ì¢Œí‘œ"""
        return torch.tensor(-self.R.T @ self.T, dtype=torch.float32, device=self.device)


class SceneDataset:
    """COLMAP ë°ì´í„°ì…‹ ë¡œë”"""
    
    def __init__(self, source_path: Path, resolution: int = -1, device: str = "cuda"):
        self.source_path = Path(source_path)
        self.resolution = resolution
        self.device = device
        
        self.cameras: List[Camera] = []
        self.point_cloud: Optional[np.ndarray] = None
        self.point_colors: Optional[np.ndarray] = None
        
        self._load_colmap()
    
    def _load_colmap(self):
        """COLMAP ë°ì´í„° ë¡œë“œ"""
        images_dir = self.source_path / "images"
        sparse_dir = self.source_path / "sparse" / "0"
        
        if not sparse_dir.exists():
            sparse_dir = self.source_path / "sparse"
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image_files = sorted(list(images_dir.glob("*.jpg")) + 
                           list(images_dir.glob("*.png")) +
                           list(images_dir.glob("*.JPG")) +
                           list(images_dir.glob("*.PNG")))
        
        if not image_files:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ: {images_dir}")
            self._create_dummy_data()
            return
        
        # COLMAP íŒŒì¼ ì²´í¬
        cameras_bin = sparse_dir / "cameras.bin"
        images_bin = sparse_dir / "images.bin"
        points3d_bin = sparse_dir / "points3D.bin"
        
        if cameras_bin.exists() and images_bin.exists():
            self._load_colmap_binary(cameras_bin, images_bin, points3d_bin, images_dir)
        else:
            print(f"âš ï¸ COLMAP íŒŒì¼ ì—†ìŒ. ë”ë¯¸ ì¹´ë©”ë¼ ì‚¬ìš©")
            self._create_dummy_cameras(image_files)
    
    def _load_colmap_binary(self, cameras_bin, images_bin, points3d_bin, images_dir):
        """COLMAP Binary íŒŒì¼ ë¡œë“œ"""
        try:
            import pycolmap
            
            reconstruction = pycolmap.Reconstruction()
            reconstruction.read_binary(str(cameras_bin.parent))
            
            # ì¹´ë©”ë¼ ë¡œë“œ
            for img_id, img in reconstruction.images.items():
                cam = reconstruction.cameras[img.camera_id]
                
                # ì´ë¯¸ì§€ ë¡œë“œ
                img_path = images_dir / img.name
                if not img_path.exists():
                    continue
                
                image = np.array(Image.open(img_path).convert("RGB"))
                height, width = image.shape[:2]
                
                # FOV ê³„ì‚°
                if cam.model_name in ["SIMPLE_PINHOLE", "PINHOLE"]:
                    fx = cam.params[0]
                    fy = cam.params[1] if len(cam.params) > 1 else fx
                else:
                    fx = fy = cam.params[0]
                
                FoVx = 2 * np.arctan(width / (2 * fx))
                FoVy = 2 * np.arctan(height / (2 * fy))
                
                # ì¹´ë©”ë¼ ë³€í™˜
                R = img.rotation_matrix()
                T = img.tvec
                
                self.cameras.append(Camera(
                    R=R, T=T, FoVx=FoVx, FoVy=FoVy,
                    image=image, image_name=img.name,
                    width=width, height=height, device=self.device
                ))
            
            # Point Cloud ë¡œë“œ
            if points3d_bin.exists():
                points = []
                colors = []
                for pt3d_id, pt3d in reconstruction.points3D.items():
                    points.append(pt3d.xyz)
                    colors.append(pt3d.color / 255.0)
                
                if points:
                    self.point_cloud = np.array(points)
                    self.point_colors = np.array(colors)
            
            print(f"   âœ… COLMAP ë¡œë“œ: {len(self.cameras)} ì¹´ë©”ë¼, {len(self.point_cloud) if self.point_cloud is not None else 0} í¬ì¸íŠ¸")
            
        except ImportError:
            print("âš ï¸ pycolmap ë¯¸ì„¤ì¹˜. ë”ë¯¸ ì¹´ë©”ë¼ ì‚¬ìš©")
            image_files = sorted(images_dir.glob("*.[jJpP][pPnN][gG]"))
            self._create_dummy_cameras(image_files)
    
    def _create_dummy_cameras(self, image_files: List[Path]):
        """ë”ë¯¸ ì¹´ë©”ë¼ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
        num_cameras = len(image_files)
        
        for i, img_path in enumerate(image_files[:50]):  # ìµœëŒ€ 50ê°œ
            image = np.array(Image.open(img_path).convert("RGB"))
            height, width = image.shape[:2]
            
            # êµ¬ë©´ ë°°ì¹˜
            angle = 2 * np.pi * i / num_cameras
            radius = 3.0
            
            # ì¹´ë©”ë¼ ìœ„ì¹˜
            cam_pos = np.array([
                radius * np.cos(angle),
                0.5,
                radius * np.sin(angle)
            ])
            
            # Look-at ë³€í™˜
            target = np.array([0, 0, 0])
            up = np.array([0, 1, 0])
            
            forward = target - cam_pos
            forward = forward / np.linalg.norm(forward)
            right = np.cross(forward, up)
            right = right / np.linalg.norm(right)
            up = np.cross(right, forward)
            
            R = np.stack([right, up, -forward], axis=1)
            T = -R.T @ cam_pos
            
            FoVx = np.pi / 3  # 60 degrees
            FoVy = FoVx * height / width
            
            self.cameras.append(Camera(
                R=R, T=T, FoVx=FoVx, FoVy=FoVy,
                image=image, image_name=img_path.name,
                width=width, height=height, device=self.device
            ))
        
        print(f"   âœ… ë”ë¯¸ ì¹´ë©”ë¼ ìƒì„±: {len(self.cameras)} ë·°")
    
    def _create_dummy_data(self):
        """ì™„ì „í•œ ë”ë¯¸ ë°ì´í„° ìƒì„±"""
        height, width = 480, 640
        
        for i in range(8):
            image = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)
            
            angle = 2 * np.pi * i / 8
            R = np.eye(3)
            T = np.array([np.cos(angle) * 3, 0.5, np.sin(angle) * 3])
            
            self.cameras.append(Camera(
                R=R, T=T, FoVx=np.pi/3, FoVy=np.pi/4,
                image=image, image_name=f"dummy_{i:03d}.jpg",
                width=width, height=height, device=self.device
            ))
        
        # ëœë¤ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        self.point_cloud = np.random.randn(10000, 3) * 0.5
        self.point_colors = np.random.rand(10000, 3)
        
        print(f"   âš ï¸ ë”ë¯¸ ë°ì´í„° ìƒì„±: {len(self.cameras)} ë·°")
    
    def __len__(self):
        return len(self.cameras)
    
    def __getitem__(self, idx):
        return self.cameras[idx]


# ============================================
# Gaussian Splatting ë Œë”ëŸ¬
# ============================================
class GaussianRenderer:
    """gsplat ê¸°ë°˜ ë Œë”ëŸ¬"""
    
    def __init__(self, sh_degree: int = 3, device: str = "cuda"):
        self.sh_degree = sh_degree
        self.device = device
        self.background = torch.tensor([0, 0, 0], dtype=torch.float32, device=device)
    
    def render(
        self,
        camera: Camera,
        gaussians: GaussianModel,
        scaling_modifier: float = 1.0
    ) -> Dict[str, torch.Tensor]:
        """
        Gaussian Splatting ë Œë”ë§
        
        Returns:
            {"render": [3, H, W], "viewspace_points": ..., "visibility_filter": ..., "radii": ...}
        """
        if not GSPLAT_AVAILABLE:
            return self._mock_render(camera, gaussians)
        
        # Gaussian ì†ì„± ê°€ì ¸ì˜¤ê¸°
        means3D = gaussians.xyz
        opacity = gaussians.opacity
        scales = gaussians.scaling * scaling_modifier
        rotations = gaussians.rotation
        shs = gaussians.features
        
        # gsplat rasterization
        try:
            # Viewmat [4, 4]
            viewmat = camera.view_matrix.unsqueeze(0)  # [1, 4, 4]
            
            # K matrix
            fx = camera.width / (2 * np.tan(camera.FoVx / 2))
            fy = camera.height / (2 * np.tan(camera.FoVy / 2))
            cx = camera.width / 2
            cy = camera.height / 2
            K = torch.tensor([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], device=self.device)
            
            # Rasterization
            renders, alphas, meta = rasterization(
                means=means3D,
                quats=rotations,
                scales=scales,
                opacities=opacity.squeeze(-1),
                colors=shs[:, 0, :],  # DC componentë§Œ ì‚¬ìš© (ê°„ì†Œí™”)
                viewmats=viewmat,
                Ks=K.unsqueeze(0),
                width=camera.width,
                height=camera.height,
                sh_degree=0,  # ê°„ì†Œí™”: DCë§Œ
                backgrounds=self.background.unsqueeze(0),
            )
            
            rendered_image = renders[0].permute(2, 0, 1)  # [3, H, W]
            
            return {
                "render": rendered_image,
                "viewspace_points": means3D,
                "visibility_filter": alphas[0] > 0,
                "radii": meta.get("radii", torch.zeros(len(means3D), device=self.device))
            }
            
        except Exception as e:
            print(f"âš ï¸ gsplat ë Œë”ë§ ì‹¤íŒ¨: {e}")
            return self._mock_render(camera, gaussians)
    
    def _mock_render(self, camera: Camera, gaussians: GaussianModel) -> Dict[str, torch.Tensor]:
        """Mock ë Œë”ë§ (gsplat ì—†ì„ ë•Œ) - í•™ìŠµìš© differentiable ë²„ì „"""
        H, W = camera.height, camera.width
        
        # Gaussian ì†ì„± (gradient ì—°ê²° ìœ ì§€)
        means3D = gaussians.xyz
        colors = gaussians.features[:, 0, :]  # DC [N, 3]
        opacities = gaussians.opacity.squeeze(-1)  # [N]
        
        # ì „ì²´ Gaussianì˜ ê°€ì¤‘ í‰ê·  ìƒ‰ìƒ ê³„ì‚° (í•­ìƒ differentiable)
        # SH to RGB
        rgb_colors = (colors * 0.28209479177387814 + 0.5).clamp(0, 1)  # [N, 3]
        
        # Opacity ê°€ì¤‘ í‰ê·  (ëª¨ë“  ì  ì‚¬ìš©)
        weights = opacities.unsqueeze(-1)  # [N, 1]
        weighted_color = (rgb_colors * weights).sum(dim=0) / (weights.sum() + 1e-8)  # [3]
        
        # ë Œë”ë§ ì´ë¯¸ì§€ ìƒì„± (ì „ì²´ë¥¼ í‰ê· ìƒ‰ìœ¼ë¡œ - ë‹¨ìˆœí™”ëœ differentiable ë Œë”ë§)
        rendered = weighted_color.view(3, 1, 1).expand(3, H, W).contiguous()
        
        return {
            "render": rendered,
            "viewspace_points": means3D.detach(),
            "visibility_filter": torch.ones(len(means3D), dtype=torch.bool, device=self.device),
            "radii": torch.ones(len(means3D), device=self.device)
        }


# ============================================
# ì†ì‹¤ í•¨ìˆ˜
# ============================================
def l1_loss(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
    return torch.abs(pred - target).mean()


def ssim_loss(pred: torch.Tensor, target: torch.Tensor, window_size: int = 11) -> torch.Tensor:
    """Structural Similarity Loss"""
    try:
        from pytorch_msssim import ssim
        return 1 - ssim(pred.unsqueeze(0), target.unsqueeze(0), data_range=1.0, size_average=True)
    except ImportError:
        # ê°„ë‹¨í•œ ëŒ€ì²´
        return l1_loss(pred, target)


def psnr(pred: torch.Tensor, target: torch.Tensor) -> float:
    """Peak Signal-to-Noise Ratio"""
    mse = F.mse_loss(pred, target)
    if mse == 0:
        return float('inf')
    return (10 * torch.log10(1.0 / mse)).item()


# ============================================
# MinIO ë°ì´í„° ê´€ë¦¬
# ============================================
class MinIODataManager:
    """MinIO ë°ì´í„° ë‹¤ìš´ë¡œë“œ/ì—…ë¡œë“œ ê´€ë¦¬"""
    
    def __init__(self, config):
        import boto3
        
        minio_cfg = config.data.minio
        self.endpoint_url = minio_cfg.endpoint
        self.bucket_raw = getattr(minio_cfg, 'bucket_raw', 'raw-data-nvs')
        self.bucket_artifacts = minio_cfg.bucket_artifacts
        
        self.s3_client = boto3.client(
            "s3",
            endpoint_url=self.endpoint_url,
            aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID", "minioadmin"),
            aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY", "minio_secure_password_2024"),
        )
    
    def download_dataset(self, s3_prefix: str, local_dir: Path) -> Path:
        """MinIOì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        local_dir = Path(local_dir)
        local_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ: s3://{self.bucket_raw}/{s3_prefix}")
        
        paginator = self.s3_client.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=self.bucket_raw, Prefix=s3_prefix)
        
        objects = []
        for page in pages:
            if 'Contents' in page:
                objects.extend(page['Contents'])
        
        if not objects:
            raise FileNotFoundError(f"ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: s3://{self.bucket_raw}/{s3_prefix}")
        
        print(f"   ğŸ“Š ì´ {len(objects)}ê°œ íŒŒì¼")
        
        for obj in tqdm(objects, desc="ë‹¤ìš´ë¡œë“œ"):
            key = obj['Key']
            rel_path = key[len(s3_prefix):].lstrip('/')
            if not rel_path:
                continue
            
            local_path = local_dir / rel_path
            local_path.parent.mkdir(parents=True, exist_ok=True)
            self.s3_client.download_file(self.bucket_raw, key, str(local_path))
        
        return local_dir
    
    def upload_artifact(self, local_path: Path, s3_key: str, bucket: Optional[str] = None):
        """ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ"""
        bucket = bucket or self.bucket_artifacts
        self.s3_client.upload_file(str(local_path), bucket, s3_key)
        print(f"   ğŸ“¤ ì—…ë¡œë“œ: s3://{bucket}/{s3_key}")


# ============================================
# ë©”ì¸ í•™ìŠµ í•¨ìˆ˜
# ============================================
def train(config):
    """NVS (3D Gaussian Splatting) í•™ìŠµ"""
    print("=" * 60)
    print("ğŸ¬ Novel View Synthesis (3D Gaussian Splatting) í•™ìŠµ")
    print("=" * 60)
    
    # gsplat ìƒíƒœ
    if GSPLAT_AVAILABLE:
        print(f"âœ… gsplat ë²„ì „: {gsplat.__version__}")
    else:
        print("âš ï¸ gsplat ë¯¸ì„¤ì¹˜ - Mock ë Œë”ëŸ¬ ì‚¬ìš©")
    
    # ì¬í˜„ì„±
    seed = config.reproducibility.seed
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    # ë””ë°”ì´ìŠ¤
    if config.hardware.device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    else:
        device = config.hardware.device
    print(f"ğŸ“± Device: {device}")
    
    if torch.cuda.is_available():
        mem = get_gpu_memory_usage()
        print(f"   ğŸ’¾ VRAM: {mem['total_mb']:.0f} MB ì´")
        torch.cuda.reset_peak_memory_stats()
    
    # ë°ì´í„° ì¤€ë¹„
    print("\nğŸ“‚ ë°ì´í„° ë¡œë”©...")
    source_path = Path(config.data.source_path)
    
    if not source_path.exists():
        try:
            data_manager = MinIODataManager(config)
            s3_prefix = str(source_path).replace("./data/", "").replace("data/", "")
            
            with tempfile.TemporaryDirectory() as tmpdir:
                source_path = data_manager.download_dataset(s3_prefix, Path(tmpdir) / "data")
        except Exception as e:
            print(f"   âš ï¸ MinIO ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # Scene ë¡œë“œ
    scene = SceneDataset(source_path, device=device)
    print(f"   ğŸ“¸ ì¹´ë©”ë¼: {len(scene)} ë·°")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = Path(config.pipeline.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    render_dir = output_dir / "renders"
    render_dir.mkdir(exist_ok=True)
    
    # Gaussian ëª¨ë¸ ìƒì„±
    print("\nğŸ§  Gaussian ëª¨ë¸ ì´ˆê¸°í™”...")
    gaussians = build_gaussian_model(config)
    
    if scene.point_cloud is not None:
        gaussians.init_from_pcd(scene.point_cloud, scene.point_colors, device)
    else:
        gaussians.init_random(config.model.init.num_points or 10000, device=device)
    
    # ë Œë”ëŸ¬
    renderer = GaussianRenderer(sh_degree=config.model.sh_degree, device=device)
    
    # ì˜µí‹°ë§ˆì´ì €
    optimizer = torch.optim.Adam(gaussians.get_param_groups(), lr=0.0, eps=1e-15)
    
    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
    def get_expon_lr_func(lr_init, lr_final, lr_delay_steps, lr_delay_mult, max_steps):
        def helper(step):
            if step < 0 or (lr_init == 0.0 and lr_final == 0.0):
                return 0.0
            if lr_delay_steps > 0:
                delay_rate = lr_delay_mult + (1 - lr_delay_mult) * np.sin(
                    0.5 * np.pi * np.clip(step / lr_delay_steps, 0, 1)
                )
            else:
                delay_rate = 1.0
            t = np.clip(step / max_steps, 0, 1)
            log_lerp = np.exp(np.log(lr_init) * (1 - t) + np.log(lr_final) * t)
            return delay_rate * log_lerp
        return helper
    
    lr_func = get_expon_lr_func(
        config.training.learning_rate.position_lr_init,
        config.training.learning_rate.position_lr_final,
        0, 1.0,
        config.training.learning_rate.position_lr_max_steps
    )
    
    # MLflow ì„¤ì •
    mlflow.set_tracking_uri(config.logging.mlflow.tracking_uri)
    mlflow.set_experiment(config.experiment.name)
    
    run_name = config.experiment.run_name or f"gs-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
    
    with mlflow.start_run(run_name=run_name):
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params({
            "sh_degree": config.model.sh_degree,
            "iterations": config.training.iterations,
            "lambda_dssim": config.training.loss.lambda_dssim,
            "densify_interval": config.training.densification.interval,
            "device": device,
            "gsplat_available": GSPLAT_AVAILABLE,
        })
        
        # íƒœê·¸
        tags = config.experiment.tags
        mlflow.set_tags({
            "project": tags.project,
            "task": tags.task,
            "method": tags.method,
        })
        
        total_iterations = config.training.iterations
        lambda_dssim = config.training.loss.lambda_dssim
        
        densify_start = config.training.densification.start_iteration
        densify_end = config.training.densification.end_iteration
        densify_interval = config.training.densification.interval
        
        print(f"\nğŸš€ í•™ìŠµ ì‹œì‘ ({total_iterations} iterations)")
        
        pbar = tqdm(range(1, total_iterations + 1), desc="Training")
        
        for iteration in pbar:
            # í•™ìŠµë¥  ì—…ë°ì´íŠ¸
            for param_group in optimizer.param_groups:
                if param_group["name"] == "xyz":
                    param_group["lr"] = lr_func(iteration)
            
            # ëœë¤ ì¹´ë©”ë¼ ì„ íƒ
            cam_idx = np.random.randint(0, len(scene))
            camera = scene[cam_idx]
            
            # ë Œë”ë§
            render_output = renderer.render(camera, gaussians)
            rendered_image = render_output["render"]
            
            # ì†ì‹¤ ê³„ì‚°
            gt_image = camera.original_image
            
            Ll1 = l1_loss(rendered_image, gt_image)
            Lssim = ssim_loss(rendered_image, gt_image)
            
            loss = (1 - lambda_dssim) * Ll1 + lambda_dssim * Lssim
            
            # ì—­ì „íŒŒ
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            
            # Densification
            if densify_start <= iteration <= densify_end and iteration % densify_interval == 0:
                gaussians.densify_and_prune(
                    grad_threshold=config.training.densification.grad_threshold,
                    opacity_threshold=config.training.densification.opacity_threshold,
                    scale_threshold=config.training.densification.scale_threshold,
                    xyz_grad=gaussians._xyz.grad if gaussians._xyz.grad is not None else None
                )
                # ì˜µí‹°ë§ˆì´ì € ì¬ì„¤ì •
                optimizer = torch.optim.Adam(gaussians.get_param_groups(), lr=0.0, eps=1e-15)
            
            # Opacity Reset
            if iteration % config.training.opacity_reset_interval == 0:
                gaussians.reset_opacity()
            
            # ë¡œê¹…
            if iteration % config.logging.log_interval == 0:
                current_psnr = psnr(rendered_image, gt_image)
                
                mlflow.log_metrics({
                    "loss": loss.item(),
                    "l1_loss": Ll1.item(),
                    "psnr": current_psnr,
                    "num_gaussians": gaussians.num_gaussians,
                }, step=iteration)
                
                log_gpu_metrics(iteration)
                
                pbar.set_postfix(loss=f"{loss.item():.4f}", psnr=f"{current_psnr:.2f}", gaussians=gaussians.num_gaussians)
            
            # ë Œë”ë§ ì €ì¥ (1000 iterationë§ˆë‹¤)
            if iteration % 1000 == 0 or iteration in config.training.test_iterations:
                with torch.no_grad():
                    # ì²« ë²ˆì§¸ ì¹´ë©”ë¼ë¡œ ë Œë”ë§
                    test_camera = scene[0]
                    test_render = renderer.render(test_camera, gaussians)["render"]
                    
                    # ì´ë¯¸ì§€ ì €ì¥
                    render_np = (test_render.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
                    render_path = render_dir / f"render_iter_{iteration:06d}.png"
                    cv2.imwrite(str(render_path), cv2.cvtColor(render_np, cv2.COLOR_RGB2BGR))
                    
                    mlflow.log_artifact(str(render_path), artifact_path="renders")
                    
                    tqdm.write(f"   ğŸ“¸ Iter {iteration}: PSNR={psnr(test_render, test_camera.original_image):.2f}, Gaussians={gaussians.num_gaussians}")
        
        # ìµœì¢… ì €ì¥
        print("\nğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥...")
        
        # Point Cloud PLY ì €ì¥
        ply_path = output_dir / "point_cloud.ply"
        gaussians.save_ply(ply_path)
        mlflow.log_artifact(str(ply_path), artifact_path="model")
        
        # Config ì €ì¥
        config_path = output_dir / "config.yaml"
        config.save(config_path)
        mlflow.log_artifact(str(config_path), artifact_path="config")
        
        # ìµœì¢… ë©”íŠ¸ë¦­
        with torch.no_grad():
            test_camera = scene[0]
            final_render = renderer.render(test_camera, gaussians)["render"]
            final_psnr = psnr(final_render, test_camera.original_image)
        
        mlflow.log_metrics({
            "final_psnr": final_psnr,
            "final_num_gaussians": gaussians.num_gaussians,
        })
        
        # GPU ìµœëŒ€ ì‚¬ìš©ëŸ‰
        if torch.cuda.is_available():
            max_mem = torch.cuda.max_memory_allocated() / (1024 ** 2)
            mlflow.log_metric("gpu/max_vram_mb", max_mem)
            print(f"   ğŸ’¾ ìµœëŒ€ VRAM ì‚¬ìš©ëŸ‰: {max_mem:.0f} MB")
        
        # MinIO ì—…ë¡œë“œ
        try:
            data_manager = MinIODataManager(config)
            s3_key = f"nvs/{run_name}/point_cloud.ply"
            data_manager.upload_artifact(ply_path, s3_key)
        except Exception as e:
            print(f"   âš ï¸ MinIO ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        print("\n" + "=" * 60)
        print("âœ… í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)
        print(f"   ğŸ“Š Final PSNR: {final_psnr:.2f} dB")
        print(f"   ğŸ¯ Final Gaussians: {gaussians.num_gaussians}")
        print(f"   ğŸ’¾ Point Cloud: {ply_path}")
        print(f"   ğŸŒ MLflow UI: {config.logging.mlflow.tracking_uri}")


def main():
    args, config = parse_args_with_config()
    train(config)


if __name__ == "__main__":
    main()
